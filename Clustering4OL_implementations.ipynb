{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 18:01:44.949928: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Absolute path is needed to load libraries \n",
    "ROOT_PATH = os.path.abspath('')\n",
    "sys.path.append(ROOT_PATH + '/lib')\n",
    "\n",
    "from lib.CustomLayer_lib import Custom_Layer\n",
    "from lib.utils import *\n",
    "from lib.Kmeans_lib import cluster_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementazione V1: Creo Kmeans con labeled + unlabeled data - (implementazione attuale nel progetto)\n",
    "Per ogni batch unisco labeled e unlabeled data. Quindi creo ogni volta un clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "n_samples = 100\n",
    "\n",
    "# Load model and features\n",
    "n_feat = 10 # Select number of features\n",
    "MODEL_PATH = 'Models/{}/'.format(n_feat)\n",
    "features_saved = np.loadtxt(MODEL_PATH + 'll_features.txt')\n",
    "labels_saved = np.loadtxt(MODEL_PATH + 'll_labels_features.txt').astype(int)\n",
    "keras_model = keras.models.load_model(MODEL_PATH + 'original_mnist_cnn.h5') # Original model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and extract the features for the labels we need\n",
    "\n",
    "# Define initial set of features\n",
    "# labels_init_list = list([1, 9, 5, 0])\n",
    "# labels_init_list = list(range(0,9))\n",
    "labels_init_list = model.std_label\n",
    "n_cluster = len(labels_init_list)\n",
    "\n",
    "# Extract from the saved features the labels that we need\n",
    "features_saved_init = []\n",
    "labels_saved_init = []\n",
    "# Extract features of digits considered in labels_init_list\n",
    "for i in range(0, len(features_saved)):\n",
    "    if labels_saved[i] in labels_init_list:\n",
    "      features_saved_init.append(features_saved[i,:])\n",
    "      labels_saved_init.append(labels_saved[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset, and add the concatenate the saved and new features together\n",
    "digits_run, labels_run, _, _ = create_dataset(n_samples, 0)\n",
    "model = Custom_Layer(keras_model)\n",
    "features_run = model.ML_frozen.predict(digits_run.reshape((n_samples,28,28,1)), verbose = False)\n",
    "\n",
    "# Convert list to nparray\n",
    "features = np.array(features_saved_init)\n",
    "features = features.astype('float32')\n",
    "labels_features = np.array(labels_saved_init)  \n",
    "\n",
    "# Concateno al vettore delle features iniziali le features della nuova batch da analizzare\n",
    "features = np.concatenate((features, features_run))\n",
    "labels_features = np.append(labels_features, labels_run).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMean Clustering\n",
    "k = KMeans(n_cluster, n_init=100)\n",
    "k.fit(features)\n",
    "\n",
    "# Find pseudolabels for each new image\n",
    "# Pseudolabels are computed by looking at the confusion matrix of the saved dataset (where ground truth is known)\n",
    "clusters_features_saved = list(k.labels_[0:len(labels_saved_init)])\n",
    "cluster_list = list(range(0,n_cluster))\n",
    "map_clu2lbl, map_lbl2clu = cluster_to_label(clusters_features_saved, list(labels_saved_init), cluster_list, labels_init_list, verbose = (model.settings.verbosity == 'DEBUG'))\n",
    "\n",
    "clusters_features = k.labels_\n",
    "\n",
    "# Compute pseudolabels\n",
    "pseudolabels = []\n",
    "for i in range(0, len(clusters_features)):\n",
    "  pseudolabel = map_clu2lbl[clusters_features[i]]\n",
    "  pseudolabels.append(pseudolabel)\n",
    "\n",
    "pseudolabels_run = pseudolabels[len(clusters_features) - len(labels_run): len(clusters_features)]\n",
    "\n",
    "err = 0 # Initialize error counter\n",
    "for i in range(len(labels_run)):\n",
    "  if pseudolabels_run[i] != labels_run[i]:\n",
    "    err += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementazione V2: Comparo due Kmeans - (funzionante)\n",
    "Runno un Kmeans sulle saved features e uno sulle nuove. Comparo le distanze tra i centroidi per determinare la corrispondenza tra i cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "n_feat = 50 # Select number of features\n",
    "n_samples = 100\n",
    "\n",
    "# Load model and features\n",
    "MODEL_PATH = 'Models/{}/'.format(n_feat)\n",
    "features_saved = np.loadtxt(MODEL_PATH + 'll_features.txt')\n",
    "labels_saved = np.loadtxt(MODEL_PATH + 'll_labels_features.txt').astype(int)\n",
    "keras_model = keras.models.load_model(MODEL_PATH + 'original_mnist_cnn.h5') # Original model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 6, 2: 1, 3: 3, 4: 5, 5: 7, 6: 8, 7: 0, 8: 4, 9: 9}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create Kmeans with the saved features\n",
    "n_cluster = 10\n",
    "k1 = KMeans(n_cluster, n_init=100)\n",
    "k1.fit(features_saved)\n",
    "\n",
    "k1.cluster_centers_.shape\n",
    "\n",
    "# Map cluster to labels\n",
    "map_clu2lbl, map_lbl2clu = cluster_to_label(k1.labels_, labels_saved, list(range(0,n_cluster)), model.std_label)\n",
    "\n",
    "map_clu2lbl\n",
    "\n",
    "# Per migliorare questa parte sarebbe da riuscire a creare i cluster usando le labels dato che sono note. Così non abbiamo errori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=10, n_init=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=10, n_init=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=10, n_init=100)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Kmeans with the new features\n",
    "# Create dataset\n",
    "digits_run, labels_run, _, _ = create_dataset(n_samples, 0)\n",
    "model = Custom_Layer(keras_model)\n",
    "features_run = model.ML_frozen.predict(digits_run.reshape((n_samples,28,28,1)), verbose = False)\n",
    "\n",
    "n_clusters = 10\n",
    "k2 = KMeans(n_clusters, n_init=100)\n",
    "k2.fit(features_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros([10,10])\n",
    "\n",
    "for i in range(0, n_cluster):\n",
    "    matrix[i,:] = k2.transform(k1.cluster_centers_[i,:].reshape(1, -1))\n",
    "\n",
    "# Rows = distances of center k1_i to the centers of k_2\n",
    "\n",
    "np.around(matrix, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 2 9 4 7 3 6 7 0] [9 0 2 6 4 1 7 5 3 3]\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 9} {0, 1, 2, 3, 4, 5, 6, 7, 9}\n"
     ]
    }
   ],
   "source": [
    "# Map cluster to cluster (argmin)\n",
    "\n",
    "# Find max in each row -> cluster corresponding to each label\n",
    "argmin_axis0 = np.argmin(matrix, axis = 0) # Min of each col \n",
    "argmin_axis1 = np.argmin(matrix, axis = 1) # Min of each row\n",
    "\n",
    "print(argmin_axis0, argmin_axis1)\n",
    "print(set(argmin_axis0), set(argmin_axis1))\n",
    "\n",
    "# Using argmin axis = 1 seems better\n",
    "map_idx = argmin_axis0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.6 14.2 14.2 15.7 20.5 17.  14.9 14.  16.9  6.9]\n",
      " [ 8.7 18.4 15.2 16.  17.1 15.  18.1 15.7 15.7 17. ]\n",
      " [16.5 16.   6.  16.5 21.4 20.4 17.7 17.4 19.5 16. ]\n",
      " [18.6 17.5 17.  16.7 16.6 19.   7.9 15.3 20.7 16.2]\n",
      " [17.3 18.9 17.8 16.   9.7 17.7 15.2 16.  18.9 19.2]\n",
      " [19.   7.  13.5 13.9 20.3 18.5 14.9 16.1 18.7 11.8]\n",
      " [15.5 15.3 14.5 13.  17.5 17.1 13.9  8.8 16.9 13.3]\n",
      " [14.8 18.4 17.8 17.2 18.9  9.6 19.4 16.2 11.4 16.7]\n",
      " [16.6 16.9 15.1 10.1 18.5 19.8 17.2 17.2 19.4 16.7]\n",
      " [18.3 14.9 15.9  8.9 17.6 18.4 15.7 15.9 19.  15.2]]\n",
      "Argmax: [1 5 2 9 4 7 3 6 7 0]\n",
      "Cluster K1 (saved) to K2 (new) map:  {1: 0, 5: 1, 2: 2, 9: 3, 4: 4, 7: 8, 3: 6, 6: 7, 0: 9}\n"
     ]
    }
   ],
   "source": [
    "# Fill dictionary with map\n",
    "map_k1_2_k2 = {}\n",
    "map_k2_2_k1 = {}\n",
    "\n",
    "for i in range(0, len(map_idx)):\n",
    "  map_k1_2_k2[map_idx[i]] = model.std_label[i]\n",
    "  map_k2_2_k1[model.std_label[i]] = map_idx[i]\n",
    "\n",
    "print(np.around(matrix, 1))\n",
    "print(\"Argmax:\", map_idx)\n",
    "print(\"Cluster K1 (saved) to K2 (new) map: \", map_k1_2_k2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 3, 3, 3, 1, 5, 9, 2, 2, 5, 7, 7, 3, 2, 7, 8, 0, 5, 8, 4, 2,\n",
       "       7, 0, 3, 0, 2, 2, 2, 4, 0, 1, 7, 0, 5, 0, 1, 0, 4, 1, 6, 5, 2, 5,\n",
       "       9, 5, 1, 0, 5, 7, 4, 3, 5, 6, 1, 0, 2, 4, 9, 2, 8, 9, 7, 4, 2, 6,\n",
       "       5, 2, 0, 4, 1, 7, 2, 8, 6, 0, 4, 6, 9, 5, 2, 1, 5, 4, 5, 2, 9, 7,\n",
       "       3, 1, 8, 7, 6, 5, 2, 4, 0, 8, 0, 3], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 4.0 Pseudolabel: 9.0 K2 cluster: 3 K1-mapped cluster: 9\n",
      "True label: 5.0 Pseudolabel: 1.0 K2 cluster: 2 K1-mapped cluster: 2\n",
      "True label: 3.0 Pseudolabel: 0.0 K2 cluster: 5 K1-mapped cluster: 7\n",
      "True label: 3.0 Pseudolabel: 7.0 K2 cluster: 1 K1-mapped cluster: 5\n",
      "True label: 2.0 Pseudolabel: 1.0 K2 cluster: 2 K1-mapped cluster: 2\n",
      "True label: 7.0 Pseudolabel: 1.0 K2 cluster: 2 K1-mapped cluster: 2\n",
      "True label: 4.0 Pseudolabel: 9.0 K2 cluster: 3 K1-mapped cluster: 9\n",
      "True label: 2.0 Pseudolabel: 1.0 K2 cluster: 2 K1-mapped cluster: 2\n",
      "True label: 4.0 Pseudolabel: 9.0 K2 cluster: 3 K1-mapped cluster: 9\n",
      "True label: 8.0 Pseudolabel: 9.0 K2 cluster: 3 K1-mapped cluster: 9\n",
      "True label: 4.0 Pseudolabel: 9.0 K2 cluster: 3 K1-mapped cluster: 9\n",
      "error: 11\n"
     ]
    }
   ],
   "source": [
    "# Find pseudolabels\n",
    "pseudolabels = np.zeros(n_samples)\n",
    "errs = 0\n",
    "for i in range(0, n_samples):\n",
    "    pseudolabels[i] = map_clu2lbl[map_k2_2_k1[k2.labels_[i]]]\n",
    "    if pseudolabels[i] != labels_run[i]:\n",
    "        errs += 1 \n",
    "        print(\"True label:\", labels_run[i],\"Pseudolabel:\", pseudolabels[i],\"K2 cluster:\", k2.labels_[i], \"K1-mapped cluster:\", map_k2_2_k1[k2.labels_[i]])\n",
    "\n",
    "# print(pseudolabels)\n",
    "print(\"error:\", errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementazione V3: Modifica di V1 che però aggiorna i cluster anzichè ricrearli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "n_samples = 10000\n",
    "\n",
    "# Load model and features\n",
    "n_feat = 10 # Select number of features\n",
    "MODEL_PATH = 'Models/{}/'.format(n_feat)\n",
    "features_saved = np.loadtxt(MODEL_PATH + 'll_features.txt')\n",
    "labels_saved = np.loadtxt(MODEL_PATH + 'll_labels_features.txt').astype(int)\n",
    "keras_model = keras.models.load_model(MODEL_PATH + 'original_mnist_cnn.h5') # Original model \n",
    "\n",
    "# Create dataset, and add the concatenate the saved and new features together\n",
    "digits_run, labels_run, _, _ = create_dataset(n_samples, 0)\n",
    "model = Custom_Layer(keras_model)\n",
    "features_run = model.ML_frozen.predict(digits_run.reshape((n_samples,28,28,1)), verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisco labels set\n",
    "labels_init_list = model.std_label\n",
    "n_cluster = len(labels_init_list)\n",
    "\n",
    "# Extract from the saved features the labels that we need\n",
    "features_saved_init = []\n",
    "labels_saved_init = []\n",
    "# Extract features of digits considered in labels_init_list\n",
    "for i in range(0, len(features_saved)):\n",
    "    if labels_saved[i] in labels_init_list:\n",
    "        features_saved_init.append(features_saved[i,:])\n",
    "        labels_saved_init.append(labels_saved[i])\n",
    "\n",
    "# Convert list to nparray\n",
    "features = np.array(features_saved_init)\n",
    "labels_features = np.array(labels_saved_init)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un dizionario per linkare le features (salvate) al cluster di appartenenza\n",
    "# creates dictionary using dictionary comprehension -> list [] is mutable object\n",
    "features_saved_dict = { key : [] for key in labels_init_list}\n",
    "\n",
    "for i in range(0, len(features_saved_init)):\n",
    "    lbl = labels_saved_init[i]\n",
    "    features_saved_dict[lbl].append(features_saved_init[i])\n",
    "\n",
    "# print(features_saved_dict[2][1][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map cluster to label: {0: 2, 1: 6, 2: 9, 3: 1, 4: 7, 5: 5, 6: 0, 7: 8, 8: 3, 9: 4}\n",
      "Errors: 570 Accuracy: 94.3%\n"
     ]
    }
   ],
   "source": [
    "# Definisco i centroidi iniziali facendo una media ndei samples nel cluster.\n",
    "# cluster_mean_dict = { key : [] for key in labels_init_list}\n",
    "cluster_mean = []\n",
    "# Converto list-of-arrays in 2D array\n",
    "for key in labels_init_list:\n",
    "  features_saved_dict[key] = np.array(features_saved_dict[key])\n",
    "  cluster_mean.append(np.mean(features_saved_dict[key], axis=0))\n",
    "\n",
    "cluster_mean = np.array(cluster_mean)\n",
    "# print(cluster_mean.shape)\n",
    "\n",
    "# Create KMeans\n",
    "kmeans = KMeans(n_cluster)\n",
    "kmeans.fit(cluster_mean)\n",
    "map_clu2lbl, map_lbl2clu = cluster_to_label(kmeans.labels_, labels_init_list, list(range(0,n_cluster)), model.std_label)\n",
    "\n",
    "# print(kmeans.predict(cluster_mean))\n",
    "print(\"Map cluster to label:\", map_clu2lbl)\n",
    "\n",
    "# Passo una nuova immagine al Kmeans. Ne determino il cluster e ne calcolo la pseudolabel\n",
    "errs = 0\n",
    "cluster_label = np.zeros(n_samples, dtype=int)\n",
    "for i in range(0, n_samples):\n",
    "    labels_new = labels_run[i]\n",
    "    features_new = np.array(features_run[i,:], dtype = type(features_saved[0,0]))\n",
    "\n",
    "    # Find the cluster for the new features\n",
    "    cluster_label[i] = kmeans.predict(features_new.reshape(1, -1))\n",
    "    pseudolabel = map_clu2lbl[cluster_label[i]]\n",
    "\n",
    "    if labels_new != pseudolabel:\n",
    "        # print(\"True label:\", labels_new,\"Pseudolabel:\", pseudolabel, \"Index:\", i)\n",
    "        errs += 1\n",
    "    else:\n",
    "        pass\n",
    "        #print(\"CORRECT!!!\", \"True label:\", labels_new,\"Pseudolabel:\", pseudolabel, \"Index:\")\n",
    "\n",
    "    # Update the cluster center\n",
    "    l_rate = 0.02\n",
    "    kmeans.cluster_centers_[cluster_label[i],:] = (kmeans.cluster_centers_[cluster_label[i],:] + features_new * l_rate)/(1 + l_rate)\n",
    "    # print(cluster_label[i])\n",
    "\n",
    "print(\"Errors:\", errs, \"Accuracy: {:.1%}\".format(1- errs/n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ora sarebbe da capire quando bisogna aggiungere un nuovo centroide, osservando le metriche interne\n",
    "\n",
    "#   kmeans.score()\n",
    "#   kmeans.transform() \n",
    "#   sklearn metrics -> es. silhouette\n",
    "# \n",
    "# Idea: faccio il clustering variando il numero di cluster e vedo di minimizzare la distanza.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7fd1b55a667aa91d3f88049cb2b0330e965cb77ee086e9d0bbb787b7ff82ca0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
