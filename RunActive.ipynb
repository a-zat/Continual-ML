{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 15:51:58.701873: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "\n",
    "import random \n",
    "from random import seed\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Absolute path is needed to load libraries \n",
    "ROOT_PATH = os.path.abspath('')\n",
    "sys.path.append(ROOT_PATH + '/lib')\n",
    "\n",
    "# from lib.Kmeans_lib import *\n",
    "# from lib.EvalMetrics import *\n",
    "\n",
    "from lib.simulation_lib import save_plots\n",
    "from lib.CustomLayer_lib import Custom_Layer, TrainSettings #, RunOneEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define settings\n",
    "from pickle import TRUE\n",
    "\n",
    "\n",
    "settings_train = TrainSettings()\n",
    "settings_train.verbosity = 'NONE'\n",
    "settings_train.clustering_labels = list(range(0, 10))\n",
    "settings_train.fill_cmtx = False\n",
    "settings_train.save_output = False\n",
    "settings_train.save_plots = False\n",
    "settings_train.mode = 'Train'\n",
    "\n",
    "settings_test = TrainSettings()\n",
    "settings_test.verbosity = 'EOEINFO'\n",
    "settings_test.clustering_labels = list(range(0, 10))\n",
    "settings_test.fill_cmtx = True\n",
    "settings_test.save_output = True\n",
    "settings_test.save_plots = True\n",
    "settings_test.mode = 'Test'\n",
    "\n",
    "\n",
    "if True:\n",
    "    list_datasets = [[3500, 500]]# Format (n_train, n_test)\n",
    "    list_features = [10, 30, 50, 100]\n",
    "    list_batches = [5, 10, 20, 40, 100]\n",
    "    iterations = 3\n",
    "\n",
    "if False:\n",
    "    list_datasets = [[50, 20]] # Format (n_train, n_test)\n",
    "    list_features = [10]\n",
    "    list_batches = [50]\n",
    "    iterations = 1   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n_train, n_test):\n",
    "  (data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "  \n",
    "  digits_train = np.zeros((n_train,28,28))\n",
    "  digits_test = np.zeros((n_test,28,28))\n",
    "  label_digits_train = np.zeros(n_train)\n",
    "  label_digits_test = np.zeros(n_test)\n",
    "\n",
    "# Select random images from the dataset\n",
    "  for i in range(0, n_train):\n",
    "    n = random.randint(0,len(data_train)-1)\n",
    "    digits_train[i,:,:] = data_train[n,:,:]\n",
    "    label_digits_train[i] = label_train[n]\n",
    "  for i in range(0, n_test): \n",
    "    m = random.randint(0,len(data_test)-1)\n",
    "    digits_test[i,:,:] = np.copy(data_test[m,:,:])\n",
    "    label_digits_test[i] = label_test[m]\n",
    "\n",
    "  img_rows, img_cols = 28, 28\n",
    "  digits_train  = digits_train.reshape(digits_train.shape[0], img_rows, img_cols, 1).astype(np.float32) / 255.0\n",
    "  digits_test = digits_test.reshape(digits_test.shape[0], img_rows, img_cols, 1).astype(np.float32) / 255.0\n",
    "\n",
    "  return digits_train, label_digits_train, digits_test, label_digits_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.Kmeans_lib import *\n",
    "from lib.CustomLayer_lib import *\n",
    "\n",
    "def RunOneEpoch(model, images, labels, features_saved, labels_saved, settings):\n",
    "\n",
    "    n_samples = images.shape[0]\n",
    "    # settings.cluster_batch_size = min(settings.cluster_batch_size, len(labels))\n",
    "    clust_err_array = []\n",
    "    model_err_array = []\n",
    "\n",
    "    # BATCH PROCESSING OF DATA\n",
    "    n_batch = int(np.ceil(n_samples / settings.cluster_batch_size))\n",
    "    images_batch = np.array_split(images, n_batch)\n",
    "    labels_batch = np.array_split(labels, n_batch)\n",
    "\n",
    "    err_clu = 0 # Clustering error (entire epoch)\n",
    "    err_mod = 0 # Model error (entire epoch)\n",
    "    pseudolabels = []\n",
    "\n",
    "    if model.ll_method == 'CWR':\n",
    "        model_cntr = 0 \n",
    "        found_digit = np.zeros(10) \n",
    "        \n",
    "    for i in range(0, n_batch):\n",
    "        batch_size = labels_batch[i].shape[0]# Current batch size\n",
    "        print(\"Starting {} batch: {}/{}\".format(settings.mode, i+1, n_batch))\n",
    "        # Features extraction\n",
    "        start1 = time.time()\n",
    "        features_batch = model.ML_frozen.predict(images_batch[i].reshape((batch_size,28,28,1)), verbose = False)\n",
    "        end1 = time.time()\n",
    "\n",
    "        # Kmean clustering\n",
    "        start2 = time.time()\n",
    "        pseudolabels_batch, err_clu_batch = k_mean_clustering(features_batch, features_saved, labels_batch[i], labels_saved, settings)\n",
    "        end2 = time.time()\n",
    "        pseudolabels.extend(pseudolabels_batch)\n",
    "        err_clu += err_clu_batch\n",
    "        clust_err_array.append(err_clu_batch)\n",
    "\n",
    "        # Last Layer update\n",
    "        err_mod_batch = 0\n",
    "        for j in range(batch_size):\n",
    "            if model.ll_method == 'OL':\n",
    "                prediction = update_ll_OL(model, features_batch[j,:], pseudolabels_batch[j])\n",
    "                \n",
    "            if model.ll_method == 'CWR':\n",
    "                \n",
    "                if(model_cntr == model.batch_size):\n",
    "                    prediction, found_digit = update_ll_CWR(model, features_batch[j,:], pseudolabels_batch[j], found_digit, True)\n",
    "                    model_cntr = 0\n",
    "                else:\n",
    "                    prediction, found_digit = update_ll_CWR(model, features_batch[j,:], pseudolabels_batch[j], found_digit, False)\n",
    "                model_cntr += 1\n",
    "\n",
    "            if(prediction != labels_batch[i][j]):  \n",
    "               err_mod_batch += 1\n",
    "\n",
    "            # Update confusion matrix - posso creare funzione in Custom_layer\n",
    "            if settings.fill_cmtx == True:\n",
    "                for k in range(0,len(model.label)):\n",
    "                    if(prediction == model.std_label[k]):\n",
    "                        p = np.copy(k)\n",
    "                    if(labels_batch[i][j] == model.std_label[k]):\n",
    "                        t = np.copy(k)\n",
    "                model.conf_matr[t,p] += 1  \n",
    "\n",
    "        model_err_array.append(err_mod_batch)\n",
    "        err_mod += err_mod_batch\n",
    "\n",
    "        if settings.verbosity == 'EOBINFO':\n",
    "            print(\"Features extraction took {:.3f} seconds and Kmean clustering took {:.3f} seconds, with {:.1%} accuracy ({} errors)\".format(end1-start1, end2-start2, 1-err_clu_batch/batch_size, err_clu_batch))\n",
    "            print(\"Batch Model errors {} ({:.1%} accuracy)\".format(err_mod_batch, 1-err_mod_batch/batch_size))\n",
    "    \n",
    "    if settings.verbosity == 'EOEINFO' or settings.verbosity == 'EOBINFO':\n",
    "        print(\"Total clustering error: {:.1%} ({}/{} errors, {:.1%} accuracy)\".format(err_clu/n_samples, err_clu, n_samples, 1-err_clu/n_samples))\n",
    "        print(\"Total model error: {:.1%} ({}/{} errors, {:.1%} accuracy)\".format(err_mod/n_samples, err_mod, n_samples, 1-err_mod/n_samples))\n",
    "\n",
    "    # return clust_err_array, model_err_array\n",
    "    if settings.save_output == True:\n",
    "        settings.datalog = list([err_clu, err_mod, clust_err_array, model_err_array])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('Results/', ignore_errors = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Train batch: 1/10\n",
      "New digit detected -> 7\n",
      "New digit detected -> 6\n",
      "Starting Train batch: 2/10\n",
      "New digit detected -> 8\n",
      "Starting Train batch: 3/10\n",
      "New digit detected -> 9\n",
      "Starting Train batch: 4/10\n",
      "Starting Train batch: 5/10\n",
      "Starting Train batch: 6/10\n",
      "Starting Train batch: 7/10\n",
      "Starting Train batch: 8/10\n",
      "Starting Train batch: 9/10\n",
      "Starting Train batch: 10/10\n",
      "Starting Test batch: 1/4\n",
      "Starting Test batch: 2/4\n",
      "Starting Test batch: 3/4\n",
      "Starting Test batch: 4/4\n",
      "Total clustering error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Total model error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Starting Train batch: 1/5\n",
      "New digit detected -> 7\n",
      "New digit detected -> 6\n",
      "New digit detected -> 8\n",
      "Starting Train batch: 2/5\n",
      "Starting Train batch: 3/5\n",
      "Starting Train batch: 4/5\n",
      "Starting Train batch: 5/5\n",
      "New digit detected -> 9\n",
      "Starting Test batch: 1/2\n",
      "Starting Test batch: 2/2\n",
      "Total clustering error: 15.0% (3/20 errors, 85.0% accuracy)\n",
      "Total model error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Starting Train batch: 1/10\n",
      "New digit detected -> 7\n",
      "New digit detected -> 6\n",
      "Starting Train batch: 2/10\n",
      "New digit detected -> 9\n",
      "New digit detected -> 8\n",
      "Starting Train batch: 3/10\n",
      "Starting Train batch: 4/10\n",
      "Starting Train batch: 5/10\n",
      "Starting Train batch: 6/10\n",
      "Starting Train batch: 7/10\n",
      "Starting Train batch: 8/10\n",
      "Starting Train batch: 9/10\n",
      "Starting Train batch: 10/10\n",
      "Starting Test batch: 1/4\n",
      "Starting Test batch: 2/4\n",
      "Starting Test batch: 3/4\n",
      "Starting Test batch: 4/4\n",
      "Total clustering error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Total model error: 15.0% (3/20 errors, 85.0% accuracy)\n",
      "Starting Train batch: 1/5\n",
      "New digit detected -> 7\n",
      "New digit detected -> 6\n",
      "New digit detected -> 9\n",
      "New digit detected -> 8\n",
      "Starting Train batch: 2/5\n",
      "Starting Train batch: 3/5\n",
      "Starting Train batch: 4/5\n",
      "Starting Train batch: 5/5\n",
      "Starting Test batch: 1/2\n",
      "Starting Test batch: 2/2\n",
      "Total clustering error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Total model error: 10.0% (2/20 errors, 90.0% accuracy)\n",
      "Starting Train batch: 1/10\n",
      "New digit detected -> 7\n",
      "New digit detected -> 8\n",
      "Starting Train batch: 2/10\n",
      "New digit detected -> 6\n",
      "Starting Train batch: 3/10\n",
      "Starting Train batch: 4/10\n",
      "Starting Train batch: 5/10\n",
      "Starting Train batch: 6/10\n",
      "New digit detected -> 9\n",
      "Starting Train batch: 7/10\n",
      "Starting Train batch: 8/10\n",
      "Starting Train batch: 9/10\n",
      "Starting Train batch: 10/10\n",
      "Starting Test batch: 1/4\n",
      "Starting Test batch: 2/4\n",
      "Starting Test batch: 3/4\n",
      "Starting Test batch: 4/4\n",
      "Total clustering error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Total model error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Starting Train batch: 1/5\n",
      "New digit detected -> 7\n",
      "New digit detected -> 8\n",
      "New digit detected -> 6\n",
      "Starting Train batch: 2/5\n",
      "Starting Train batch: 3/5\n",
      "New digit detected -> 9\n",
      "Starting Train batch: 4/5\n",
      "Starting Train batch: 5/5\n",
      "Starting Test batch: 1/2\n",
      "Starting Test batch: 2/2\n",
      "Total clustering error: 25.0% (5/20 errors, 75.0% accuracy)\n",
      "Total model error: 25.0% (5/20 errors, 75.0% accuracy)\n",
      "Starting Train batch: 1/10\n",
      "New digit detected -> 7\n",
      "New digit detected -> 8\n",
      "Starting Train batch: 2/10\n",
      "New digit detected -> 6\n",
      "Starting Train batch: 3/10\n",
      "Starting Train batch: 4/10\n",
      "Starting Train batch: 5/10\n",
      "Starting Train batch: 6/10\n",
      "Starting Train batch: 7/10\n",
      "Starting Train batch: 8/10\n",
      "Starting Train batch: 9/10\n",
      "Starting Train batch: 10/10\n",
      "Starting Test batch: 1/4\n",
      "New digit detected -> 9\n",
      "Starting Test batch: 2/4\n",
      "Starting Test batch: 3/4\n",
      "Starting Test batch: 4/4\n",
      "Total clustering error: 25.0% (5/20 errors, 75.0% accuracy)\n",
      "Total model error: 20.0% (4/20 errors, 80.0% accuracy)\n",
      "Starting Train batch: 1/5\n",
      "New digit detected -> 7\n",
      "New digit detected -> 8\n",
      "New digit detected -> 6\n",
      "Starting Train batch: 2/5\n",
      "Starting Train batch: 3/5\n",
      "Starting Train batch: 4/5\n",
      "Starting Train batch: 5/5\n",
      "Starting Test batch: 1/2\n",
      "New digit detected -> 9\n",
      "Starting Test batch: 2/2\n",
      "Total clustering error: 15.0% (3/20 errors, 85.0% accuracy)\n",
      "Total model error: 20.0% (4/20 errors, 80.0% accuracy)\n"
     ]
    }
   ],
   "source": [
    "# File structure:\n",
    "# /Results/dataset_\n",
    "\n",
    "if False:\n",
    "    list_datasets = [[50, 20]] # Format (n_train, n_test)\n",
    "    list_features = [10, 30]\n",
    "    list_batches = [5, 10]\n",
    "    iterations = 2   \n",
    "\n",
    "for n_train, n_test in list_datasets:\n",
    "    for idx in range(1, iterations+1):\n",
    "\n",
    "        # Create directory and log file\n",
    "        if settings_test.save_output == True:\n",
    "            \n",
    "            RESULTS_PATH = 'Results/ds{}_{}_{}/'.format(idx,n_train, n_test)\n",
    "            os.makedirs(RESULTS_PATH, exist_ok = True)\n",
    "            settings_test.save_path = RESULTS_PATH\n",
    "            with open(RESULTS_PATH + 'output_log.txt', 'w') as new_file:  # overwrite if already exists\n",
    "                # File headers\n",
    "                new_file.write(\"# Dataset: {}, n_train = {}, n_test = {} \\n\".format(iterations,n_train, n_test))\n",
    "                new_file.write(\"# \\n\")\n",
    "                new_file.write(\"# FEATURES\\t; BATCH_SZ\\t; CST_ERRS\\t; CST_ACC\\t; MDL_ERRS\\t; MDL_ACC\\t;\\t TIME\\t; CST_ERR_ARRAY\\t; MDL_ERR_ARRAY\\n\")\n",
    "                new_file.close()\n",
    "\n",
    "        # Create dataset\n",
    "        digits_train, label_digits_train, digits_test, label_digits_test = create_dataset(n_train, n_test)\n",
    "\n",
    "        for n_feat in list_features:\n",
    "\n",
    "            #  Set model and features\n",
    "            MODEL_PATH = 'Models/{}/'.format(n_feat)\n",
    "            features_saved = np.loadtxt(MODEL_PATH + 'll_features.txt')\n",
    "            labels_features_saved = np.loadtxt(MODEL_PATH + 'll_labels_features.txt').astype(int)\n",
    "            keras_model = keras.models.load_model(MODEL_PATH + 'original_mnist_cnn.h5')  # Original model\n",
    "\n",
    "            for batch_size in list_batches:\n",
    "\n",
    "                # Initialize model\n",
    "                Model = Custom_Layer(keras_model)\n",
    "                Model.title = 'OL'\n",
    "                Model.filename = 'OL'\n",
    "                Model.l_rate = 0.01\n",
    "                Model.batch_size = 8\n",
    "                Model.ll_method = 'OL'\n",
    "\n",
    "                startTime = time.time()\n",
    "                # Train the model\n",
    "                settings_train.cluster_batch_size = batch_size\n",
    "                RunOneEpoch(Model, digits_train, label_digits_train,features_saved, labels_features_saved, settings_train)\n",
    "\n",
    "                # Test the model\n",
    "                settings_test.cluster_batch_size = batch_size\n",
    "                RunOneEpoch(Model, digits_test, label_digits_test,features_saved, labels_features_saved, settings_test)\n",
    "                endTime = time.time()\n",
    "\n",
    "                # Save log\n",
    "                # Unpack datalog output\n",
    "                clust_err = settings_test.datalog[0]\n",
    "                model_err = settings_test.datalog[1]\n",
    "                clust_err_array = settings_test.datalog[2]\n",
    "                model_err_array = settings_test.datalog[3]\n",
    "\n",
    "                if settings_test.save_output == True:\n",
    "                    with open(RESULTS_PATH + 'output_log.txt', 'a') as new_file:  \n",
    "                        new_file.write(\"\\t{:3d} \\t;\\t {:3d} \\t;\\t\".format(n_feat,batch_size))\n",
    "                        new_file.write(\"{:3d} \\t;\\t {:.1%} \\t;\\t{:3d} \\t;\\t {:.1%} \\t;\\t\".format(clust_err, 1-clust_err/n_test, model_err, 1-model_err/n_test))\n",
    "                        new_file.write(\"{:.3f}\\t;\\t\".format(endTime-startTime))\n",
    "                        new_file.write(\"{}\\t;\\t{}\\n\".format(clust_err_array, model_err_array))\n",
    "                    new_file.close()\n",
    "\n",
    "                #  Save plots\n",
    "                if settings_test.save_plots == True:\n",
    "                    save_plots(Model, RESULTS_PATH + '/Plots', 'Features_{}_Batch_{}'.format(n_feat, batch_size))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7fd1b55a667aa91d3f88049cb2b0330e965cb77ee086e9d0bbb787b7ff82ca0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
