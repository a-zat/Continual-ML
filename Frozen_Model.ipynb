{"cells":[{"cell_type":"markdown","metadata":{"id":"D8g3_OkUNOuD"},"source":["## **Import the TensorFlow library**"]},{"cell_type":"markdown","metadata":{"id":"UKk-D3IZkkbE"},"source":["This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to be applied on STM32 Nucleo Board."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5736,"status":"ok","timestamp":1665998604312,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"XCqcQuaBLNgF"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-10-18 00:56:39.963164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import backend as K\n","import random\n","import os\n","import csv \n","\n","# Absolute path is needed to load libraries \n","import sys\n","ROOT_PATH = os.path.abspath('')\n","sys.path.append(ROOT_PATH + '/lib')\n","\n","from lib.frozen_lib import *"]},{"cell_type":"markdown","metadata":{},"source":["## Options (could be moved to another file)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Define High and Low sets\n","low_set = set(range(0,6))\n","high_set = set(range(6,10))\n","\n","# test elements\n","n_elem_low = 10   # Number of elements for each label to add in data_low_test\n","n_elem_high = 10  # Number of elements for each label to add in data_high_test"]},{"cell_type":"markdown","metadata":{"id":"VT8C9aeAMdSE"},"source":["Load MNIST dataset and split in training and test"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1665998604945,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"mNfeJ2bbNDET","outputId":"08220356-e5f0-4c96-e364-9ca188f39331"},"outputs":[{"name":"stdout","output_type":"stream","text":["The original dataset shapes are\n","    Train dataset shape: (60000, 28, 28)\n","    Test dataset shape:  (10000, 28, 28)\n"]}],"source":["(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n","print('The original dataset shapes are')\n","print(f'    Train dataset shape: {data_train.shape}')\n","print(f'    Test dataset shape:  {data_test.shape}')"]},{"cell_type":"markdown","metadata":{"id":"LaAIs1HlrltM"},"source":["Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# New separation script\n","train_samples = label_train.shape[0]\n","test_samples  = label_test.shape[0]\n","\n","trainLow_samples = 0\n","testLow_samples = 0\n","for lbl in low_set:\n","    trainLow_samples += (label_train == lbl).sum()\n","    testLow_samples += (label_test == lbl).sum()\n","\n","# previous code:\n","# trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n","# testLow_samples = np.sum(np.where(label_test < 6, 1, 0))\n","\n","# Split train dataset in high and low\n","data_low_train   = np.zeros([trainLow_samples,28,28])\n","label_low_train  = np.zeros(trainLow_samples)\n","data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n","label_high_train = np.zeros(train_samples-trainLow_samples)\n","\n","j,k = 0,0\n","for i in range(0,train_samples):  \n","    if(label_train[i] in low_set):\n","        data_low_train[j,:,:] = data_train[i,:,:]\n","        label_low_train[j]    = label_train[i]\n","        j+=1\n","    else:\n","        data_high_train[k,:,:] = data_train[i,:,:]\n","        label_high_train[k]    = label_train[i]\n","        k+=1\n","\n","\n","# Split test dataset in high and low. Number of testing elements is predefined\n","n_low = n_elem_low * len(low_set)\n","n_high = n_elem_high * len(high_set)\n","\n","data_low_test   = np.zeros([n_low,28,28])\n","label_low_test  = np.zeros(n_low)\n","data_high_test  = np.zeros([n_high,28,28])\n","label_high_test = np.zeros(n_high)\n","\n","digits_set = low_set.union(high_set)\n","counter = {x: 0 for x in digits_set}\n","\n","j,k = 0,0\n","for i in range(0,test_samples):  \n","    if(label_test[i] in low_set):\n","        if(counter[label_test[i]] < n_elem_low):\n","            data_low_test[j,:,:] = data_test[i,:,:]\n","            label_low_test[j]    = label_test[i]\n","            counter[label_test[i]] += 1\n","            j += 1\n","    else:\n","        if(counter[label_test[i]] < n_elem_high):\n","            data_high_test[k,:,:] = data_test[i,:,:]\n","            label_high_test[k]    = label_test[i]\n","            counter[label_test[i]] += 1\n","            k += 1   "]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1665998606607,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"bgVHZlEqqBr7","outputId":"2e943778-c123-485f-ac5e-f0962afac393"},"outputs":[{"name":"stdout","output_type":"stream","text":["5\n","9.0\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Randomly check if dataset that I created are filled correctly\n","num = int(random.uniform(0,20))\n","print(num)\n","plt.imshow(data_high_test[num], cmap=\"gray\") # Import the image\n","print(label_high_test[num])\n","plt.show() # Plot the image"]},{"cell_type":"markdown","metadata":{"id":"MTx7YrtENh3F"},"source":["## Data preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665998606608,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"lU_tKzkCse1H"},"outputs":[],"source":["# Image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# Data formatting\n","if K.image_data_format() == 'channels_first':\n","    data_low_train  = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n","    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n","    data_low_test   = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n","    data_high_test  = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n","    input_shape     = (1, img_rows, img_cols)\n","else:\n","    data_low_train  = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n","    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n","    data_low_test   = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n","    data_high_test  = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n","    input_shape     = (img_rows, img_cols, 1)\n","\n","# Normalization\n","data_low_train  = data_low_train.astype(np.float32) / 255.0\n","data_high_train = data_high_train.astype(np.float32) / 255.0\n","data_low_test   = data_low_test.astype(np.float32) / 255.0\n","data_high_test  = data_high_test.astype(np.float32) / 255.0\n"]},{"cell_type":"markdown","metadata":{"id":"-NZNND6XFXFw"},"source":["Normalize the dataset"]},{"cell_type":"markdown","metadata":{"id":"TNaCD_O0RPDs"},"source":["## **BUILD THE MODEL**"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1665998606609,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"dewlaeUUlFpw"},"outputs":[],"source":["# Options\n","\n","# Model \n","TRAIN_MODEL_1 = True\n","TRAIN_MODEL_2 = False\n","TRAIN_MODEL_3 = False\n","\n","# Training options\n","batch_size = 32\n","epochs     = 10\n","validation_split = 0.1\n","optimizer  = \"adam\"\n","loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metrics    = ['accuracy']"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2175,"status":"ok","timestamp":1665998608776,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"vZVNdEatp8L2","outputId":"07100436-8659-4bfc-8245-7423327141b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 24, 8)         584       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 12, 12, 8)        0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 32)        2336      \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 32)          9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 4, 4, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 4, 4, 32)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 6)                 3078      \n","                                                                 \n","=================================================================\n","Total params: 15,326\n","Trainable params: 15,326\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]},{"name":"stderr","output_type":"stream","text":["2022-10-18 00:56:47.015131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["if(TRAIN_MODEL_1):\n","    model = Sequential()\n","    \n","    model.add(Conv2D(8, kernel_size=(3,3), activation='relu',input_shape=input_shape))\n","    model.add(Conv2D(8, (3,3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Conv2D(32, (3,3), activation='relu'))\n","    model.add(Conv2D(32, (3,3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(6,activation='softmax'))\n","\n","    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","    print(model.summary())"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665998608777,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"EhPlI-Ojmj4u"},"outputs":[],"source":["#if(TRAIN_MODEL_1):\n","#    tf.keras.utils.plot_model(model, show_shapes=True, to_file='naive_inception_module.png')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665998608778,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"Cige2fQHFXGB"},"outputs":[],"source":["# METHOD 2\n","# This model is a bit larger and should be much more precise in the feature extraction\n","if(TRAIN_MODEL_2):\n","    model2 = Sequential()\n","    model2.add(Conv2D(32, (3, 3), input_shape = input_shape))\n","    model2.add(Conv2D(32, (3, 3), activation = \"relu\"))\n","    model2.add(MaxPooling2D(pool_size = (2, 2)))\n","    model2.add(Dropout(0.2))\n","    model2.add(Flatten())\n","    model2.add(Dense(128, activation = \"relu\"))\n","    model2.add(Dropout(0.2))\n","    model2.add(Dense(6, activation = \"softmax\"))\n","\n","    model2.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","    model2.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665998608778,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"pxMSgJ2ymj4v"},"outputs":[],"source":["if(TRAIN_MODEL_3):\n","\n","    l = tf.keras.layers # syntax shortcut\n","\n","    def fire(x, squeeze, expand):\n","        y = l.Conv2D(filters=squeeze, kernel_size=1, padding='same', activation='relu')(x)\n","        y1 = l.Conv2D(filters=expand//2, kernel_size=1, padding='same', activation='relu')(y)\n","        y3 = l.Conv2D(filters=expand//2, kernel_size=3, padding='same', activation='relu')(y)\n","        return tf.keras.layers.concatenate([y1, y3])\n","\n","    # this is to make it behave similarly to other Keras layers\n","    def fire_module(squeeze, expand):\n","        return lambda x: fire(x, squeeze, expand)\n","\n","    # usage:\n","    x = tf.keras.layers.Input(shape=[*input_shape]) # input is 192x192 pixels RGB\n","\n","    y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(x)\n","    y = fire_module(24, 48)(y)\n","    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","    y = fire_module(24, 48)(y)\n","    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","    y = fire_module(24, 48)(y)\n","    y = tf.keras.layers.GlobalAveragePooling2D()(y)\n","    y = tf.keras.layers.Dense(6, activation='softmax')(y)\n","\n","    model3 = tf.keras.Model(x, y)\n","    model3.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","    model3.summary()"]},{"cell_type":"markdown","metadata":{"id":"P_3CoNfUFXGE"},"source":["## TRAIN THE MODEL"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":214784,"status":"ok","timestamp":1665998823555,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"ZRk1oPJmTCM2","outputId":"5e03bbf3-013c-497a-814f-8b2c5e1bc26b","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/Users/andrea/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"name":"stdout","output_type":"stream","text":["1013/1013 [==============================] - 13s 13ms/step - loss: 0.1452 - accuracy: 0.9514 - val_loss: 0.0406 - val_accuracy: 0.9903\n","Epoch 2/10\n","1013/1013 [==============================] - 13s 13ms/step - loss: 0.0434 - accuracy: 0.9859 - val_loss: 0.0289 - val_accuracy: 0.9947\n","Epoch 3/10\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.0288 - val_accuracy: 0.9933\n","Epoch 4/10\n","1013/1013 [==============================] - 12s 11ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0206 - val_accuracy: 0.9953\n","Epoch 5/10\n","1013/1013 [==============================] - 12s 11ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0243 - val_accuracy: 0.9936\n","Epoch 6/10\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0196 - val_accuracy: 0.9958\n","Epoch 7/10\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0220 - val_accuracy: 0.9953\n","Epoch 8/10\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0144 - val_accuracy: 0.9969\n","Epoch 9/10\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0219 - val_accuracy: 0.9964\n","Epoch 10/10\n","1013/1013 [==============================] - 12s 11ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0194 - val_accuracy: 0.9956\n","2/2 [==============================] - 0s 4ms/step - loss: 4.8472e-04 - accuracy: 1.0000\n","\n","Test accuracy: 1.0\n"]}],"source":["if(TRAIN_MODEL_1):\n","    \n","    labels_prova = keras.utils.to_categorical(label_low_train, len(low_set))\n","\n","    train_hist = model.fit(data_low_train, label_low_train, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n","    \n","  # Evaluate the model performance\n","    test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n","\n","    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1665998823555,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"h_oS2hh3FXGO","scrolled":false},"outputs":[],"source":["if(TRAIN_MODEL_2):\n","\n","    labels_prova = keras.utils.to_categorical(label_low_train, 6)\n","\n","    model2.fit(data_low_train, labels_prova, epochs = epochs, batch_size = batch_size, validation_split = validation_split )\n","\n","    # Evaluate the model performance\n","    test_loss, test_acc = model2.evaluate(data_low_test, keras.utils.to_categorical(label_low_test, 6))\n","\n","    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665998823556,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"ljevV8Snmj4x"},"outputs":[],"source":["if(TRAIN_MODEL_3):\n","    \n","    labels_modified_test = keras.utils.to_categorical(label_low_train, 6)\n","    \n","    model3.fit(data_low_train, labels_modified_test, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n","\n","    # Evaluate the model performance\n","    test_loss, test_acc = model3.evaluate(data_low_test, keras.utils.to_categorical(label_low_test, 6))\n","\n","    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "]},{"cell_type":"markdown","metadata":{"id":"tI3aR1l4pqhS"},"source":["## TEST THE MODEL"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665998823557,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"UxawR_zdmj41"},"outputs":[],"source":["#confusion_matrix = testing(data_low_test, label_low_test, model)\n","#hostiry_training_plot(train_hist)\n","#plot_Accuracy(confusion_matrix)\n","#plot_ConfusionMatrix(confusion_matrix)\n","#plot_Table(confusion_matrix)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665998823558,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"AVNdx-gjlhze"},"outputs":[],"source":["if(TRAIN_MODEL_1):\n","    model_test = model\n","elif(TRAIN_MODEL_2):\n","    model_test = model2\n","elif(TRAIN_MODEL_3):\n","    model_test = model3"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":889,"status":"ok","timestamp":1665998824439,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"piwc0fbspvlc","outputId":"3323284b-2b6a-46d0-86ef-93331db212fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 7ms/step\n"]}],"source":["predictions = model_test.predict(data_low_test)   # Make prediction of entire dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1665998824441,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"_L_MP6pejCGk","outputId":"d57c00f9-084b-4d17-91bc-4088144af115"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction =  4\n","True label =  4\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 600x300 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["num = int(random.uniform(0, predictions.shape[0])) \n","\n","print(\"Prediction = \" , np.argmax(predictions[num]))\n","print(\"True label = \" , int(label_low_test[num]))\n","\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","\n","plot_image(num, predictions[num], label_low_test, data_low_test)\n","plt.subplot(1,2,2)\n","\n","plot_value_array(num, predictions[num], label_low_test)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ye7xyl_-vkkk"},"source":["# **SAVE MODELS, WEIGHTS AND FEATURES**"]},{"cell_type":"markdown","metadata":{},"source":["### SAVE THE ORIGINAL MODEL"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1604,"status":"ok","timestamp":1665998826031,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"rjFdtesdvqzf","outputId":"e4805664-ade9-4882-b44d-d394ce4f8c10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss: 0.0004847217642236501\n","Test accuracy: 1.0\n","Save ORIGINAL MODEL as mnist_cnn.h5\n"]}],"source":["ROOT_PATH = os.path.abspath('')\n","SAVE_MODEL_PATH = ROOT_PATH + \"/Models\"\n","\n","ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"/Original_model/\" \n","\n","print('Test loss:', test_loss)\n","print('Test accuracy:', test_acc)\n","print('Save ORIGINAL MODEL as mnist_cnn.h5')\n","model_test.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n","\n","info = save_info(batch_size, epochs, metrics, optimizer, \"SparseCategoricalCrossentropy\")\n","save_summary_model(model_test, ORIGINAL_MODEL_PATH, info, \"original\")"]},{"cell_type":"markdown","metadata":{"id":"1nPOwtTnFXGk"},"source":["Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."]},{"cell_type":"markdown","metadata":{"id":"Rk84TZDvyjW4"},"source":["### SAVE THE FROZEN MODEL"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2615,"status":"ok","timestamp":1665998828642,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"qQzEf-OKFXGl","outputId":"b2705bd2-5e13-4f3b-ab10-380814467e1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 24, 8)         584       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 12, 12, 8)        0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 32)        2336      \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 32)          9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 4, 4, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 4, 4, 32)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n","=================================================================\n","Total params: 12,248\n","Trainable params: 12,248\n","Non-trainable params: 0\n","_________________________________________________________________\n","Save FROZEN MODEL model as mnist_cnn.h5\n"]}],"source":["# CREATE AND SAVE THE FROZEN MODEL\n","frozen_model = keras.models.Sequential(model_test.layers[:-1])\n","frozen_model.summary()\n","frozen_model.compile()\n","\n","FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"/Frozen_model/\"\n","\n","print('Save FROZEN MODEL model as mnist_cnn.h5')\n","info = save_info(batch_size, epochs, metrics, optimizer, \"SparseCategoricalCrossentropy\")\n","frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n","save_summary_model(frozen_model, FROZEN_MODEL_PATH, info, \"frozen\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### SAVE LL WEIGHTS (Last Layer)"]},{"cell_type":"markdown","metadata":{"id":"f1wsEHInFXGn"},"source":["Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2083,"status":"ok","timestamp":1665998830721,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"NOvcRsOVFXGn","outputId":"56870492-0e67-4c4c-8500-4fe73aec7af6"},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of the last layer weights is: (512, 6)\n","The shape of the last layer biases is: (6,)\n"]}],"source":["ll_weights = np.array(model_test.layers[-1].get_weights()[0])   # get last layer weights from TF model\n","ll_biases  = np.array(model_test.layers[-1].get_weights()[1])   # get last layer biases from TF model\n","print(f'The shape of the last layer weights is: {ll_weights.shape}')\n","print(f'The shape of the last layer biases is: {ll_biases.shape}')\n","\n","# -------- WEIGHTS\n","# NB: the filof weights is separated in smaller rows (338 float values on each row)\n","# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n","with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n","\n","    for j in range(0, ll_weights.shape[1]):\n","        for i in range(0, ll_weights.shape[0]): \n","            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n","                new_file.write('\\n')\n","                \n","            new_file.write(str(ll_weights[i,j]))\n","            \n","            if(i == ll_weights.shape[0]-1):\n","                new_file.write('\\n')\n","            elif((i+1)%338 == 0):\n","                dummy = 0\n","            else:\n","                new_file.write(',')\n","\n","new_file.close()\n","\n","\n","# -------- BIASES\n","with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n","\n","    for i in range(0, ll_biases.shape[0]):     \n","        new_file.write(str(ll_biases[i])) \n","        if(i!=ll_biases.shape[0]-1):\n","            new_file.write(',')\n","new_file.close()"]},{"cell_type":"markdown","metadata":{},"source":["### SAVE FEATURES"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["data_test = np.concatenate((data_low_test, data_high_test))\n","label_test = np.concatenate((label_low_test, label_high_test))\n","\n","# Compute predictions\n","features = frozen_model.predict(data_test, verbose = False)\n","\n","if(n_elem_low == n_elem_high):\n","  n_elem = str(n_elem_low)\n","else:\n","  n_elem = str(n_elem_low) + '_' + str(n_elem_high)\n","\n","np.savetxt(ORIGINAL_MODEL_PATH +'/'+'ll_features_'+ n_elem + '.txt',features, fmt='%.3f')\n","\n","with open(ORIGINAL_MODEL_PATH +'/'+'ll_features_'+ n_elem + '.txt', 'w') as new_file:\n","\n","    for i in range(0, features.shape[0]):\n","        for j in range(0, features.shape[1]): \n","            if features[i,j] != 0:\n","              str1 = '%.3f '%features[i,j]\n","            else:\n","              str1 = '0 '\n","\n","            new_file.write(str1)\n","            \n","        new_file.write('\\n')     \n","\n","new_file.close()\n","\n","np.savetxt(ORIGINAL_MODEL_PATH +'/'+'ll_labels_features_'+ n_elem + '.txt',label_test, fmt='%1d')"]},{"cell_type":"markdown","metadata":{"id":"pAbOTJtahc7J"},"source":["# Pruning"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":921,"status":"ok","timestamp":1665998835888,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"xZpZ_mxvhnkI","outputId":"0e87d262-41ac-48ea-d177-6b9818ef4a45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," prune_low_magnitude_conv2d   (None, 26, 26, 8)        154       \n"," (PruneLowMagnitude)                                             \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 24, 24, 8)        1162      \n"," 1 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_max_poo  (None, 12, 12, 8)        1         \n"," ling2d (PruneLowMagnitude)                                      \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 10, 10, 32)       4642      \n"," 2 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 8, 8, 32)         18466     \n"," 3 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_max_poo  (None, 4, 4, 32)         1         \n"," ling2d_1 (PruneLowMagnitude                                     \n"," )                                                               \n","                                                                 \n"," prune_low_magnitude_dropout  (None, 4, 4, 32)         1         \n","  (PruneLowMagnitude)                                            \n","                                                                 \n"," prune_low_magnitude_flatten  (None, 512)              1         \n","  (PruneLowMagnitude)                                            \n","                                                                 \n"," prune_low_magnitude_dense (  (None, 6)                6152      \n"," PruneLowMagnitude)                                              \n","                                                                 \n","=================================================================\n","Total params: 30,580\n","Trainable params: 15,326\n","Non-trainable params: 15,254\n","_________________________________________________________________\n","Epoch 1/5\n","   5/1013 [..............................] - ETA: 28s - loss: 0.0920 - accuracy: 0.9812       WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0238s vs `on_train_batch_end` time: 0.0247s). Check your callbacks.\n","1013/1013 [==============================] - 21s 14ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.0167 - val_accuracy: 0.9958\n","Epoch 2/5\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0172 - val_accuracy: 0.9958\n","Epoch 3/5\n","1013/1013 [==============================] - 15s 15ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.0172 - val_accuracy: 0.9953\n","Epoch 4/5\n","  60/1013 [>.............................] - ETA: 14s - loss: 0.0076 - accuracy: 0.9974"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [24], line 47\u001b[0m\n\u001b[1;32m     40\u001b[0m logdir \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39mmkdtemp()\n\u001b[1;32m     42\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m     43\u001b[0m   tfmot\u001b[39m.\u001b[39msparsity\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mUpdatePruningStep(),\n\u001b[1;32m     44\u001b[0m   tfmot\u001b[39m.\u001b[39msparsity\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mPruningSummaries(log_dir\u001b[39m=\u001b[39mlogdir),\n\u001b[1;32m     45\u001b[0m ]\n\u001b[0;32m---> 47\u001b[0m model_for_pruning\u001b[39m.\u001b[39;49mfit(data_low_train, label_low_train,\n\u001b[1;32m     48\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mbatch_size, epochs\u001b[39m=\u001b[39;49mepochs, validation_split\u001b[39m=\u001b[39;49mvalidation_split, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m     52\u001b[0m \u001b[39m####\u001b[39;00m\n\u001b[1;32m     53\u001b[0m _, model_for_pruning_accuracy \u001b[39m=\u001b[39m model_for_pruning\u001b[39m.\u001b[39mevaluate(data_low_test, label_low_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from tensorflow.keras.models import load_model\n","import tensorflow_model_optimization as tfmot\n","\n","\n","####\n","prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","# Compute end step to finish pruning after n epochs.\n","batch_size = 32\n","epochs = 5\n","validation_split = 0.1  # 10% of training set will be used for validation set. \n","\n","num_images = data_low_train.shape[0] * (1 - validation_split)\n","end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n","\n","# Define model for pruning.\n","pruning_params = {\n","    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n","                                                               final_sparsity=0.80,\n","                                                               begin_step=0,\n","                                                               end_step=end_step)\n","}\n","\n","\n","model_for_pruning = prune_low_magnitude(model_test, **pruning_params)\n","\n","# `prune_low_magnitude` requires a recompile.\n","\n","# Select appropriate optimizer\n","model_for_pruning.compile(optimizer='adam',\n","                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                          metrics=['accuracy'])\n","\n","model_for_pruning.summary()\n","\n","\n","\n","\n","#####\n","logdir = tempfile.mkdtemp()\n","\n","callbacks = [\n","  tfmot.sparsity.keras.UpdatePruningStep(),\n","  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n","]\n","\n","model_for_pruning.fit(data_low_train, label_low_train,\n","                    batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks)\n","\n","\n","\n","####\n","_, model_for_pruning_accuracy = model_for_pruning.evaluate(data_low_test, label_low_test, verbose=0)\n","\n","print('Original test accuracy: ', test_acc)\n","print('Pruned test accuracy:   ', model_for_pruning_accuracy)\n","\n","\n","####\n","# First, create a compressible model for TensorFlow\n","\n","PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"/Pruned_model\"\n","\n","\n","model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","model_for_export.save(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.h5', include_optimizer=False)\n","\n","\n","\n","\n","#####\n","# Then, create a compressible model for TFLite\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n","pruned_tflite_model = converter.convert()\n","\n","with open(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.tflite', 'wb') as f:\n","    f.write(pruned_tflite_model)\n","\n","\n","#####\n","print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n","print(\"Size of gzipped pruned Keras model  : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.h5')))\n","print(\"Size of gzipped pruned TFlite model : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.tflite')))\n","\n","\n","\n","\n","#####\n","frozen_pruned_model = keras.models.Sequential(model_for_pruning.layers[:-1])\n","frozen_pruned_model.summary()\n","frozen_pruned_model.compile()\n","\n","FROZEN_PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"/Frozen_Pruned_model\"\n","\n","print('Save FROZEN PRUNED MODEL model as OMV_Frozen_pruned_cnn.h5')\n","frozen_pruned_model.save(FROZEN_PRUNED_MODEL_PATH + \"OMV_Frozen_pruned_cnn.h5\")\n","info = save_info(batch_size, epochs, metrics, optimizer, \"SparseCategoricalCrossentropy\")\n","save_summary_model(frozen_pruned_model, FROZEN_PRUNED_MODEL_PATH, info, 'frozen')\n","\n","\n","\n","\n","#####\n","model_for_export2 = tfmot.sparsity.keras.strip_pruning(frozen_pruned_model)\n","model_for_export2.save(PRUNED_MODEL_PATH + '/OMV_Frozen_pruned_cnn.h5', include_optimizer=False)\n","\n","\n","\n","\n","###\n","converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export2)\n","pruned_tflite_fmodel = converter.convert()\n","\n","with open(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.tflite', 'wb') as f:\n","    f.write(pruned_tflite_fmodel)\n","\n","\n","\n","####\n","data_test = np.concatenate((data_low_test, data_high_test))\n","label_test = np.concatenate((label_low_test, label_high_test))\n","features = frozen_pruned_model.predict(data_test)\n","\n","\n","\n","\n","####\n","count = 0\n","\n","for i in range(0, len(features[:,1])):\n","  for j in range(0, len(features[1,:])):\n","    if features[i,j] == 0:\n","      count +=1\n","\n","print(count/len(features[:,1])/len(features[1,:])*100)\n","\n","\n","\n","\n","######\n","\n","np.savetxt(FROZEN_PRUNED_MODEL_PATH +'/'+'ll_features_p_10.txt',features, fmt='%.3f')\n","\n","with open(FROZEN_PRUNED_MODEL_PATH +'/'+'ll_features_p_10.txt', 'w') as new_file:\n","\n","    for i in range(0, features.shape[0]):\n","        for j in range(0, features.shape[1]): \n","            if features[i,j] != 0:\n","              str1 = '%.3f '%features[i,j]\n","            else:\n","              str1 = '0 '\n","\n","            new_file.write(str1)\n","            \n","        new_file.write('\\n')     \n","\n","new_file.close()\n","\n","np.savetxt(FROZEN_PRUNED_MODEL_PATH +'/'+'ll_labels_features_p_10.txt',label_test, fmt='%1d')"]},{"cell_type":"markdown","metadata":{"id":"SNAsXyqvh-nP"},"source":["Tflite frozen pruned"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.7 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"f7fd1b55a667aa91d3f88049cb2b0330e965cb77ee086e9d0bbb787b7ff82ca0"}}},"nbformat":4,"nbformat_minor":0}
