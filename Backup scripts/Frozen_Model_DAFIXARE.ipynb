{"cells":[{"cell_type":"markdown","metadata":{"id":"D8g3_OkUNOuD"},"source":["## **Import the TensorFlow library**"]},{"cell_type":"markdown","metadata":{"id":"UKk-D3IZkkbE"},"source":["This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to be applied on STM32 Nucleo Board."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5736,"status":"ok","timestamp":1665998604312,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"XCqcQuaBLNgF"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-10-25 23:06:09.675036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import backend as K\n","import random\n","import os\n","import csv \n","\n","# Absolute path is needed to load libraries \n","import sys\n","ROOT_PATH = os.path.abspath('')\n","sys.path.append(ROOT_PATH + '/lib')\n","\n","from lib.frozen_lib import *"]},{"cell_type":"markdown","metadata":{},"source":["## Options (could be moved to another file)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Define High and Low sets\n","low_set = set(range(0,6))\n","high_set = set(range(6,10))\n","\n","# test elements\n","n_elem_low = 100   # Number of elements for each label to add in data_low_test\n","n_elem_high = 100  # Number of elements for each label to add in data_high_test"]},{"cell_type":"markdown","metadata":{"id":"VT8C9aeAMdSE"},"source":["Load MNIST dataset and split in training and test"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1665998604945,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"mNfeJ2bbNDET","outputId":"08220356-e5f0-4c96-e364-9ca188f39331"},"outputs":[{"name":"stdout","output_type":"stream","text":["The original dataset shapes are\n","    Train dataset shape: (60000, 28, 28)\n","    Test dataset shape:  (10000, 28, 28)\n"]}],"source":["(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n","print('The original dataset shapes are')\n","print(f'    Train dataset shape: {data_train.shape}')\n","print(f'    Test dataset shape:  {data_test.shape}')"]},{"cell_type":"markdown","metadata":{"id":"LaAIs1HlrltM"},"source":["Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","# New separation script\n","train_samples = label_train.shape[0]\n","test_samples  = label_test.shape[0]\n","\n","trainLow_samples = 0\n","testLow_samples = 0\n","for lbl in low_set:\n","    trainLow_samples += (label_train == lbl).sum()\n","    testLow_samples += (label_test == lbl).sum()\n","\n","# previous code:\n","# trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n","# testLow_samples = np.sum(np.where(label_test < 6, 1, 0))\n","\n","# Split train dataset in high and low\n","data_low_train   = np.zeros([trainLow_samples,28,28])\n","label_low_train  = np.zeros(trainLow_samples)\n","data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n","label_high_train = np.zeros(train_samples-trainLow_samples)\n","\n","j,k = 0,0\n","for i in range(0,train_samples):  \n","    if(label_train[i] in low_set):\n","        data_low_train[j,:,:] = data_train[i,:,:]\n","        label_low_train[j]    = label_train[i]\n","        j+=1\n","    else:\n","        data_high_train[k,:,:] = data_train[i,:,:]\n","        label_high_train[k]    = label_train[i]\n","        k+=1\n","\n","\n","# Split test dataset in high and low. Number of testing elements is predefined\n","n_low = n_elem_low * len(low_set)\n","n_high = n_elem_high * len(high_set)\n","\n","data_low_test   = np.zeros([n_low,28,28])\n","label_low_test  = np.zeros(n_low)\n","data_high_test  = np.zeros([n_high,28,28])\n","label_high_test = np.zeros(n_high)\n","\n","digits_set = low_set.union(high_set)\n","counter = {x: 0 for x in digits_set}\n","\n","j,k = 0,0\n","for i in range(0,test_samples):  \n","    if(label_test[i] in low_set):\n","        if(counter[label_test[i]] < n_elem_low):\n","            data_low_test[j,:,:] = data_test[i,:,:]\n","            label_low_test[j]    = label_test[i]\n","            counter[label_test[i]] += 1\n","            j += 1\n","    else:\n","        if(counter[label_test[i]] < n_elem_high):\n","            data_high_test[k,:,:] = data_test[i,:,:]\n","            label_high_test[k]    = label_test[i]\n","            counter[label_test[i]] += 1\n","            k += 1   "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1665998606607,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"bgVHZlEqqBr7","outputId":"2e943778-c123-485f-ac5e-f0962afac393"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n","9.0\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Randomly check if dataset that I created are filled correctly\n","num = int(random.uniform(0,20))\n","print(num)\n","plt.imshow(data_high_test[num], cmap=\"gray\") # Import the image\n","print(label_high_test[num])\n","plt.show() # Plot the image"]},{"cell_type":"markdown","metadata":{"id":"MTx7YrtENh3F"},"source":["## Data preprocessing"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665998606608,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"lU_tKzkCse1H"},"outputs":[],"source":["# Image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# Data formatting\n","if K.image_data_format() == 'channels_first':\n","    data_low_train  = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n","    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n","    data_low_test   = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n","    data_high_test  = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n","    input_shape     = (1, img_rows, img_cols)\n","else:\n","    data_low_train  = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n","    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n","    data_low_test   = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n","    data_high_test  = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n","    input_shape     = (img_rows, img_cols, 1)\n","\n","# Normalization\n","data_low_train  = data_low_train.astype(np.float32) / 255.0\n","data_high_train = data_high_train.astype(np.float32) / 255.0\n","data_low_test   = data_low_test.astype(np.float32) / 255.0\n","data_high_test  = data_high_test.astype(np.float32) / 255.0\n"]},{"cell_type":"markdown","metadata":{"id":"TNaCD_O0RPDs"},"source":["## **BUILD THE MODEL**"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1665998606609,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"dewlaeUUlFpw"},"outputs":[],"source":["# Options\n","\n","# Model \n","TRAIN_MODEL_1 = True\n","TRAIN_MODEL_2 = False\n","TRAIN_MODEL_3 = False\n","\n","# Training options\n","batch_size = 32\n","epochs     = 10\n","validation_split = 0.1\n","optimizer  = \"adam\"\n","loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metrics    = ['accuracy']"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2175,"status":"ok","timestamp":1665998608776,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"vZVNdEatp8L2","outputId":"07100436-8659-4bfc-8245-7423327141b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 24, 8)         584       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 12, 12, 8)        0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 32)        2336      \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 32)          9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 4, 4, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 4, 4, 32)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 6)                 3078      \n","                                                                 \n","=================================================================\n","Total params: 15,326\n","Trainable params: 15,326\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]},{"name":"stderr","output_type":"stream","text":["2022-10-25 23:06:17.274427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["if(TRAIN_MODEL_1):\n","    model = Sequential()\n","    \n","    model.add(Conv2D(8, kernel_size=(3,3), activation='relu',input_shape=input_shape))\n","    model.add(Conv2D(8, (3,3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Conv2D(32, (3,3), activation='relu'))\n","    model.add(Conv2D(32, (3,3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(6,activation='softmax'))\n","\n","    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","    print(model.summary())"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665998608777,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"EhPlI-Ojmj4u"},"outputs":[],"source":["#if(TRAIN_MODEL_1):\n","#    tf.keras.utils.plot_model(model, show_shapes=True, to_file='naive_inception_module.png')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665998608778,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"Cige2fQHFXGB"},"outputs":[],"source":["# METHOD 2\n","# This model is a bit larger and should be much more precise in the feature extraction\n","if(TRAIN_MODEL_2):\n","    model2 = Sequential()\n","    model2.add(Conv2D(32, (3, 3), input_shape = input_shape))\n","    model2.add(Conv2D(32, (3, 3), activation = \"relu\"))\n","    model2.add(MaxPooling2D(pool_size = (2, 2)))\n","    model2.add(Dropout(0.2))\n","    model2.add(Flatten())\n","    model2.add(Dense(128, activation = \"relu\"))\n","    model2.add(Dropout(0.2))\n","    model2.add(Dense(6, activation = \"softmax\"))\n","\n","    model2.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","    model2.summary()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665998608778,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"pxMSgJ2ymj4v"},"outputs":[],"source":["if(TRAIN_MODEL_3):\n","\n","    l = tf.keras.layers # syntax shortcut\n","\n","    def fire(x, squeeze, expand):\n","        y = l.Conv2D(filters=squeeze, kernel_size=1, padding='same', activation='relu')(x)\n","        y1 = l.Conv2D(filters=expand//2, kernel_size=1, padding='same', activation='relu')(y)\n","        y3 = l.Conv2D(filters=expand//2, kernel_size=3, padding='same', activation='relu')(y)\n","        return tf.keras.layers.concatenate([y1, y3])\n","\n","    # this is to make it behave similarly to other Keras layers\n","    def fire_module(squeeze, expand):\n","        return lambda x: fire(x, squeeze, expand)\n","\n","    # usage:\n","    x = tf.keras.layers.Input(shape=[*input_shape]) # input is 192x192 pixels RGB\n","\n","    y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(x)\n","    y = fire_module(24, 48)(y)\n","    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","    y = fire_module(24, 48)(y)\n","    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","    y = fire_module(24, 48)(y)\n","    y = tf.keras.layers.GlobalAveragePooling2D()(y)\n","    y = tf.keras.layers.Dense(6, activation='softmax')(y)\n","\n","    model3 = tf.keras.Model(x, y)\n","    model3.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","    model3.summary()"]},{"cell_type":"markdown","metadata":{"id":"P_3CoNfUFXGE"},"source":["## TRAIN THE MODEL"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":214784,"status":"ok","timestamp":1665998823555,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"ZRk1oPJmTCM2","outputId":"5e03bbf3-013c-497a-814f-8b2c5e1bc26b","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/Users/andrea/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"name":"stdout","output_type":"stream","text":[" 412/1013 [===========>..................] - ETA: 7s - loss: 0.2678 - accuracy: 0.9131"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m(TRAIN_MODEL_1):\n\u001b[1;32m      3\u001b[0m     labels_prova \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(label_low_train, \u001b[39mlen\u001b[39m(low_set))\n\u001b[0;32m----> 5\u001b[0m     train_hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(data_low_train, label_low_train, epochs \u001b[39m=\u001b[39;49m epochs, batch_size \u001b[39m=\u001b[39;49m batch_size, validation_split \u001b[39m=\u001b[39;49m validation_split)\n\u001b[1;32m      7\u001b[0m   \u001b[39m# Evaluate the model performance\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(data_low_test, label_low_test)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if(TRAIN_MODEL_1):\n","    \n","    labels_prova = keras.utils.to_categorical(label_low_train, len(low_set))\n","\n","    train_hist = model.fit(data_low_train, label_low_train, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n","    \n","  # Evaluate the model performance\n","    test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n","\n","    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1665998823555,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"h_oS2hh3FXGO","scrolled":false},"outputs":[],"source":["if(TRAIN_MODEL_2):\n","\n","    labels_prova = keras.utils.to_categorical(label_low_train, 6)\n","\n","    model2.fit(data_low_train, labels_prova, epochs = epochs, batch_size = batch_size, validation_split = validation_split )\n","\n","    # Evaluate the model performance\n","    test_loss, test_acc = model2.evaluate(data_low_test, keras.utils.to_categorical(label_low_test, 6))\n","\n","    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665998823556,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"ljevV8Snmj4x"},"outputs":[],"source":["if(TRAIN_MODEL_3):\n","    \n","    labels_modified_test = keras.utils.to_categorical(label_low_train, 6)\n","    \n","    model3.fit(data_low_train, labels_modified_test, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n","\n","    # Evaluate the model performance\n","    test_loss, test_acc = model3.evaluate(data_low_test, keras.utils.to_categorical(label_low_test, 6))\n","\n","    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "]},{"cell_type":"markdown","metadata":{"id":"tI3aR1l4pqhS"},"source":["## TEST THE MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665998823557,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"UxawR_zdmj41"},"outputs":[],"source":["#confusion_matrix = testing(data_low_test, label_low_test, model)\n","#hostiry_training_plot(train_hist)\n","#plot_Accuracy(confusion_matrix)\n","#plot_ConfusionMatrix(confusion_matrix)\n","#plot_Table(confusion_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665998823558,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"AVNdx-gjlhze"},"outputs":[],"source":["if(TRAIN_MODEL_1):\n","    model_test = model\n","elif(TRAIN_MODEL_2):\n","    model_test = model2\n","elif(TRAIN_MODEL_3):\n","    model_test = model3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":889,"status":"ok","timestamp":1665998824439,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"piwc0fbspvlc","outputId":"3323284b-2b6a-46d0-86ef-93331db212fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["19/19 [==============================] - 0s 3ms/step\n"]}],"source":["predictions = model_test.predict(data_low_test)   # Make prediction of entire dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1665998824441,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"_L_MP6pejCGk","outputId":"d57c00f9-084b-4d17-91bc-4088144af115"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction =  1\n","True label =  1\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAekAAAESCAYAAADZmy1NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATL0lEQVR4nO3de3CU9b3H8U8S2QDJJtzShIUEUS493CmUiOihjFgU8JSOUzrI1ECx9TihQmntVUEHkDN6LK2CCqKgtZLBaqBHOTIIhAhNEdAooSeIGiE0JAEvJAskIcnv/MGYGmA3YZvsfkPerxlmyv72t883tvHdJ7vPkyjnnBMAADAnOtIDAACASyPSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOuivQAANqG+vp6lZSUyOv1KioqKtLjAG2ac06VlZXy+XyKjg58vkykATRLSUmJUlNTIz0GcEUpLi5W7969A64TaQDN4vV6JZ3/l0pCQkKEpwkuvzRf49eOD+sxd87eqREpI8J6TLRdFRUVSk1Nbfi+CoRIA2iWL3/EnZCQYD7S8afjpY5hPqY33vw/F9jT1FtHfHAMAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYFTIl2Bx9yGgZTT3zkMA2p+QI83dh4CW1dSdhwC0PyH/3/am7pIC4PLwPQXgQiFHmh9xAy2L7ykAF+INMAAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABh1VaQHQNt21113BVxbvXp10L3r168PuDZz5syQZwKAKwVn0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjuAQL/5Lly5cHXHPOhXESALjycCYNAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFNdJI6jbb7896HqnTp3CNAkAtD+cSQMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABjFddKQx+MJuLZo0aKge6OiogKu1dbWBt2bm5sbfDAAaOc4kwYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYxSVY0I033hhwbfDgwUH3BrvMasGCBUH3rlq1KvhgANDOcSYNAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFNdJQ9OnTw95b15eXsC1lStXhvy6AADOpAEAMItIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGcQlWO7B48eKg63feeWfIr71kyZKQ9wIAguNMGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCiuk24Hpk2bFnTd4/EEXNu4cWPQvTk5OZc/EACgWTiTBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABjFJVhXgPvuuy/o+pAhQ4Ku79+/P+BaRkZG0L21tbVB1wEAoeNMGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCiuk24jbr/99oBrv/jFL4Ludc4FXd++fXvANb/fH3wwAECr4UwaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCKSAMAYBSRBgDAKK6TNsLn8wVdX758ecC17t27B937/PPPB11v6jprAEBkcCYNAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpLsIzIyMgIut6rV6+Aa039KsrFixeHNBMAILI4kwYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjCLSAAAYRaQBADCK66TDqEOHDgHXbrnllpBf98UXXwy6/vHHH4f82gCAyOFMGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUl2CF0U9/+tOAazfccEPQvYWFhQHXfvazn4U8EwDALs6kAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjOI66TCaOnVqwLUzZ84E3btkyZKAaydPngx5JgCAXZxJAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIziEqwWtGbNmqDr6enpAdc2bdoUdO/69etDmgkA0HZxJg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAU10lfpl69egVcu/nmm4Pu3b17d8C1jIyMkGcCAFyZOJMGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwiuukL9OIESMCrvXu3Tvo3lmzZgVcO3v2bIgTAQCuVJxJAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIziEqwLdO3aNej6mjVrAq49++yzQfcG+1WVAABciDNpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo7hO+gK1tbVB1wsLCwOuLV26NOjempqakGYCALRPnEkDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEYRaQAAjOISrAtUVlYGXZ8wYUKYJgEAtHecSQMAYBSRBgDAKCINAIBRRBoAAKOINAAARhFpAACMItIAABhFpAEAMIpIAwBgFJEGAMAoIg0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEaFHGnnXEvOAbR7fE8BuFDIka6srGzJOYB2j+8pABe6KtSNPp9PxcXF8nq9ioqKasmZgHbFOafKykr5fL5IjwLAmJAjHR0drd69e7fkLEC7lZiYGOkRABjEB8cAADCKSAMAYBSRBgDAKCINAIBRRBoAAKOINAAARoV8CRaA9uXLO6JVVFREeJKm+Sv9UlX4j1kRZ/+fDWz48vuoqTsNRjnuRQigGY4dO6bU1NRIjwFcUYqLi4Pec4RIA2iW+vp6lZSUtMpdBisqKpSamqri4mIlJCS06Gu3pRmszMEMrT/DV+80GB0d+J1nftyNy1ZTV6NBKwfphe++oOtTr2/Wnr+f+Lu+/cdv69DcQ4rzxLXyhGgN4bjLYEJCQkQDaWUGK3MwQ+vO0Jw7DfLBsRaUeyRXt62/Tb7HfIp6KEobCzc2ued45XHd8codGvDEAEU/FK35b8y/5PNePviyvr7i6+q4pKOGPjVUmw9vbrTunNPCHQvV87Ge6rS0kya+MFGHPz3csF5dW60fZP9ACcsSNOCJAXrz4zcb7X9096P6yeafNOvrfHrf0+rbtW+jQC/NXarrn71enZd2Vpf/6nLRnkFJg3Rd7+v0u7zfNesYAAAi3aJO15zW8OThWjl5ZbP3VNdVK6lzku7/9/s1PGX4JZ/z1+K/asYrMzRn5By9e/e7mjZwmqZlTVNBeUHDcx7Z/Yge3/O4np7ytPbctUdxnjhNenGSqmrPf3pm9f7V2l+yX3lz8vTjUT/WHa/c0fCBhaLPi/TMO89o6U1Lm5zXOacVb6/QnJFzGj1eU1ej7w36nu4ZfU/AvbNHzNZT+55SbX1tk8cBAEhyaBV6UC77/7Iva8/4tePdvP+dd9Hj01+e7qb8aUqjx9KfSXd3/8/dzjnn6uvrXcp/p7hHdz/asP7F2S9c7OJYt/7Aeuecc/e8do/75dZfOuecO1NzxulBuXJ/uXPOuUl/nORe/furzZpx7z/2uuiHol1FVcUl19e+u9YlLku85Fp1bbWLXRzr3vzozWYdC+1HVVWVW7RokauqqmrXM1iZgxnszMCZdBuQV5yniddMbPTYpGsnKe9YniSp6IsilfpLGz0nsWOi0nunK6/4/HOGJw/XrqO7dPbcWW35aIt6xvdUj8499Kf3/6SOV3XUd//tu82a5a0jb2lA9wHyxnov++vwxHg0ImWE3jr61mXvxZUtNjZWDz74oGJjY9v1DFbmYAY7M/DBsTag1F+q5LjkRo8lxyer1F/asC7p4ufEJav09Pm1H478od4ve1+DnhykHp17aMP3Nujzqs+1MGehcjJydP/2+5VVkKVru12r5/7jOfVK6HXJWY6cOiKfN/Tfe+zz+nTk1JGQ9wNAe0Kk24kOMR20ckrj98pnb5qte8fcq3dL39XGwo167z/f0yO7H9G9b9yrV6a/csnXOXvurDpe1THkOTp16KQz586EvB8A2hN+3N0GpMSnqOx0WaPHyvxlSolPaViXdPFzTpcpJS7lkq+5o2iHDpYf1Nwxc5XzSY4m95+sOE+cpg+erpxPcgLO0qNzD31+9vOQv5bPzn6mpM5JIe8HgPaESLcBY1PHalvRtkaPbf14q8b2HitJ6tulr1LiU7Tt438+p6K6QnuO7dHY1LEXvV5VbZUyN2dq1dRViomOUV19nc7VnZMknas/p7r6uoCzjOw5UoUnC5u8lV0gBeUFGpkyMqS9ANDe8OPuFuSv8evDzz5s+HvR50XKL81Xt07dlJaYFnBffml+w/4TZ04ovzRfnhiPBiUNkiTNS5+n8evG67G/PqYpA6YoqyBL+0r2afVtqyVJUVFRmp8+X0veWqL+3furb5e+emDHA/J5fZr29WkXHW/xzsWa3H+yRvY8H8txaeN039b7NHvkbK14e4XGpY0LOOuEqyfIX+PXwRMHNeRrQxoeP3rqqD47+5mOnjqqOlfX8DX169ZP8Z54SdInX3yif1T846IPwQEAAojY58qvQDuKdjg9qIv+ZGRnBN13qT19lvdp9JwNBRvcgCcGOM9ijxu8crB7/YPXG63X19e7B7Y/4JIfTXaxi2PdTc/f5A6dPHTRsQ6UHXD9Hu/n/NX+hsfq6uvcPa/d4xKWJbhvrv6mO/zp4aDzTn95uvvV1l81eiwjO+OSX8eOoh0Nz3k492E36Y+Tgr422qcVK1a4Pn36uNjYWDdmzBi3Z8+esB5/586dburUqa5nz55OksvOzg7r8R9++GE3evRoFx8f75KSktx3vvMdV1hYGNYZnnzySTd06FDn9Xqd1+t11113ndu8eXNYZ7jQsmXLnCQ3b968sB530aJFTlKjPwMHDgzrDF8i0rhs75W+57726NdcZXVls/dU11a7tOVpbteRXa04GdqirKws5/F43HPPPecOHjzofvSjH7kuXbq4srKysM2wefNm99vf/ta9+uqrEYn0pEmT3Nq1a11BQYHLz893kydPdmlpac7v9ze9uYX85S9/ca+//rr74IMP3KFDh9xvfvMb16FDB1dQUBC2Gb7q7bffdldffbUbNmxYRCI9ePBgd/z48YY/J06cCOsMXyLSCMnad9e690vfb/bzD3962D299+lWnAht1ZgxY1xmZmbD3+vq6pzP53PLli2LyDyRiPSFysvLnSS3c+fOiM7RtWtXt2bNmrAft7Ky0vXv399t3brVjR8/PiKRHj58eFiPGQgfHENIZo2YpaHJQ5v9/H7d+unu0Xe34kRoi2pqarR//35NnPjPzylER0dr4sSJysvLi+BkkXXq1ClJUrdu3SJy/Lq6OmVlZen06dMaO/biD5+2tszMTE2ZMqXR/y7C7fDhw/L5fLrmmms0c+ZMHT16NCJz8MExABFz8uRJ1dXVKTn5ghvxJCersLAwQlNFVn19vebPn69x48ZpyJAhTW9oQQcOHNDYsWNVVVWl+Ph4ZWdna9CgQWGdISsrS++884727t0b1uN+VXp6utatW6eBAwfq+PHjeuihh3TjjTeqoKBAXu/l323xX0GkAcCQzMxMFRQUaNeuXWE/9sCBA5Wfn69Tp07pz3/+szIyMrRz586whbq4uFjz5s3T1q1b1bFj6DdN+lfdeuutDf952LBhSk9PV58+fbRhwwbNmTMnyM6WR6QBREyPHj0UExOjsrILbsRTVqaUlEvfiOdKNnfuXL322mvKzc1t9d/dfSkej0f9+vWTJI0aNUp79+7VH/7wB61atSosx9+/f7/Ky8v1jW98o+Gxuro65ebmasWKFaqurlZMTExYZvmqLl26aMCAAfrwww+bfnIL4z1pABHj8Xg0atQobdv2zxvx1NfXa9u2bRF5LzRSnHOaO3eusrOztX37dvXt2zfSI0k6/99FdXV12I5300036cCBA8rPz2/4M3r0aM2cOVP5+fkRCbQk+f1+ffTRR+rZs2fYj82ZNICIWrBggTIyMjR69GiNGTNGv//973X69GnNnj07bDP4/f5GZ0lFRUXKz89Xt27dlJYW+EZELSUzM1MvvfSSNm3aJK/Xq9LS878YJzExUZ06dWr140vSr3/9a916661KS0tTZWWlXnrpJeXk5GjLli1hOb4keb3ei96Hj4uLU/fu3cP6/vzPf/5z3XbbberTp49KSkq0aNEixcTEaMaMGWGb4UtEGkBEff/739eJEye0cOFClZaWasSIEXrjjTcu+jBZa9q3b58mTJjQ8PcFCxZIkjIyMrRu3bpWP/5TTz0lSfrWt77V6PG1a9dq1qxZrX58SSovL9edd96p48ePKzExUcOGDdOWLVt08803h+X4lhw7dkwzZszQp59+qqSkJN1www3629/+pqSk8P/egSjnQrwJMwAAaFW8Jw0AgFFEGgAAo4g0AABGEWkAAIwi0gAAGEWkAQAwikgDAGAUkQYAwCgiDQCAUUQaAACjiDQAAEb9PwEEF9G+4P6/AAAAAElFTkSuQmCC","text/plain":["<Figure size 600x300 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["num = int(random.uniform(0, predictions.shape[0])) \n","\n","print(\"Prediction = \" , np.argmax(predictions[num]))\n","print(\"True label = \" , int(label_low_test[num]))\n","\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","\n","plot_image(num, predictions[num], label_low_test, data_low_test)\n","plt.subplot(1,2,2)\n","\n","plot_value_array(num, predictions[num], label_low_test)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ye7xyl_-vkkk"},"source":["# **SAVE MODELS, WEIGHTS AND FEATURES**"]},{"cell_type":"markdown","metadata":{},"source":["### SAVE THE ORIGINAL MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1604,"status":"ok","timestamp":1665998826031,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"rjFdtesdvqzf","outputId":"e4805664-ade9-4882-b44d-d394ce4f8c10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss: 0.03432123363018036\n","Test accuracy: 0.9900000095367432\n","Save ORIGINAL MODEL as mnist_cnn.h5\n"]}],"source":["ROOT_PATH = os.path.abspath('')\n","#SAVE_MODEL_PATH = ROOT_PATH + \"/Models\"\n","\n","\n","\n","#ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"/Original_model/\" \n","\n","print('Test loss:', test_loss)\n","print('Test accuracy:', test_acc)\n","print('Save ORIGINAL MODEL as mnist_cnn.h5')\n","model_test.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n","\n","info = save_info(batch_size, epochs, metrics, optimizer, \"SparseCategoricalCrossentropy\")\n","save_summary_model(model_test, ORIGINAL_MODEL_PATH, info, \"original\")"]},{"cell_type":"markdown","metadata":{"id":"1nPOwtTnFXGk"},"source":["Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."]},{"cell_type":"markdown","metadata":{"id":"Rk84TZDvyjW4"},"source":["### SAVE THE FROZEN MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2615,"status":"ok","timestamp":1665998828642,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"qQzEf-OKFXGl","outputId":"b2705bd2-5e13-4f3b-ab10-380814467e1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_8 (Conv2D)           (None, 26, 26, 8)         80        \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 24, 24, 8)         584       \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 12, 12, 8)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 10, 10, 32)        2336      \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 8, 8, 32)          9248      \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 4, 4, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 4, 4, 32)          0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 512)               0         \n","                                                                 \n","=================================================================\n","Total params: 12,248\n","Trainable params: 12,248\n","Non-trainable params: 0\n","_________________________________________________________________\n","Save FROZEN MODEL model as mnist_cnn.h5\n"]}],"source":["# CREATE AND SAVE THE FROZEN MODEL\n","frozen_model = keras.models.Sequential(model_test.layers[:-1])\n","frozen_model.summary()\n","frozen_model.compile()\n","\n","FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"/Frozen_model/\"\n","\n","print('Save FROZEN MODEL model as mnist_cnn.h5')\n","info = save_info(batch_size, epochs, metrics, optimizer, \"SparseCategoricalCrossentropy\")\n","frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n","save_summary_model(frozen_model, FROZEN_MODEL_PATH, info, \"frozen\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### SAVE LL WEIGHTS (Last Layer)"]},{"cell_type":"markdown","metadata":{"id":"f1wsEHInFXGn"},"source":["Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2083,"status":"ok","timestamp":1665998830721,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"NOvcRsOVFXGn","outputId":"56870492-0e67-4c4c-8500-4fe73aec7af6"},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of the last layer weights is: (512, 6)\n","The shape of the last layer biases is: (6,)\n"]}],"source":["ll_weights = np.array(model_test.layers[-1].get_weights()[0])   # get last layer weights from TF model\n","ll_biases  = np.array(model_test.layers[-1].get_weights()[1])   # get last layer biases from TF model\n","print(f'The shape of the last layer weights is: {ll_weights.shape}')\n","print(f'The shape of the last layer biases is: {ll_biases.shape}')\n","\n","# -------- WEIGHTS\n","# NB: the filof weights is separated in smaller rows (338 float values on each row)\n","# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n","with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n","\n","    for j in range(0, ll_weights.shape[1]):\n","        for i in range(0, ll_weights.shape[0]): \n","            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n","                new_file.write('\\n')\n","                \n","            new_file.write(str(ll_weights[i,j]))\n","            \n","            if(i == ll_weights.shape[0]-1):\n","                new_file.write('\\n')\n","            elif((i+1)%338 == 0):\n","                dummy = 0\n","            else:\n","                new_file.write(',')\n","\n","new_file.close()\n","\n","\n","# -------- BIASES\n","with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n","\n","    for i in range(0, ll_biases.shape[0]):     \n","        new_file.write(str(ll_biases[i])) \n","        if(i!=ll_biases.shape[0]-1):\n","            new_file.write(',')\n","new_file.close()"]},{"cell_type":"markdown","metadata":{},"source":["### SAVE FEATURES"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_test = np.concatenate((data_low_test, data_high_test))\n","label_test = np.concatenate((label_low_test, label_high_test))\n","\n","# Compute predictions\n","features = frozen_model.predict(data_test, verbose = False)\n","\n","if(n_elem_low == n_elem_high):\n","  n_elem = str(n_elem_low)\n","else:\n","  n_elem = str(n_elem_low) + '_' + str(n_elem_high)\n","\n","np.savetxt(ORIGINAL_MODEL_PATH +'/'+'ll_features_'+ n_elem + '.txt',features, fmt='%.3f')\n","\n","with open(ORIGINAL_MODEL_PATH +'/'+'ll_features_'+ n_elem + '.txt', 'w') as new_file:\n","\n","    for i in range(0, features.shape[0]):\n","        for j in range(0, features.shape[1]): \n","            if features[i,j] != 0:\n","              str1 = '%.3f '%features[i,j]\n","            else:\n","              str1 = '0 '\n","\n","            new_file.write(str1)\n","            \n","        new_file.write('\\n')     \n","\n","new_file.close()\n","\n","np.savetxt(ORIGINAL_MODEL_PATH +'/'+'ll_labels_features_'+ n_elem + '.txt',label_test, fmt='%1d')"]},{"cell_type":"markdown","metadata":{"id":"pAbOTJtahc7J"},"source":["# Pruning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":921,"status":"ok","timestamp":1665998835888,"user":{"displayName":"Giovanni Poletti","userId":"02119684520637616053"},"user_tz":-120},"id":"xZpZ_mxvhnkI","outputId":"0e87d262-41ac-48ea-d177-6b9818ef4a45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," prune_low_magnitude_conv2d_  (None, 26, 26, 8)        154       \n"," 8 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 24, 24, 8)        1162      \n"," 9 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_max_poo  (None, 12, 12, 8)        1         \n"," ling2d_4 (PruneLowMagnitude                                     \n"," )                                                               \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 10, 10, 32)       4642      \n"," 10 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 8, 8, 32)         18466     \n"," 11 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_max_poo  (None, 4, 4, 32)         1         \n"," ling2d_5 (PruneLowMagnitude                                     \n"," )                                                               \n","                                                                 \n"," prune_low_magnitude_dropout  (None, 4, 4, 32)         1         \n"," _2 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_flatten  (None, 512)              1         \n"," _2 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_dense_2  (None, 6)                6152      \n","  (PruneLowMagnitude)                                            \n","                                                                 \n","=================================================================\n","Total params: 30,580\n","Trainable params: 15,326\n","Non-trainable params: 15,254\n","_________________________________________________________________\n","Epoch 1/5\n","   6/1013 [..............................] - ETA: 11s - loss: 0.0043 - accuracy: 1.0000  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0121s). Check your callbacks.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0121s). Check your callbacks.\n"]},{"name":"stdout","output_type":"stream","text":["1013/1013 [==============================] - 15s 12ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0207 - val_accuracy: 0.9964\n","Epoch 2/5\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0196 - val_accuracy: 0.9950\n","Epoch 3/5\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0185 - val_accuracy: 0.9953\n","Epoch 4/5\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0215 - val_accuracy: 0.9950\n","Epoch 5/5\n","1013/1013 [==============================] - 12s 12ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0204 - val_accuracy: 0.9958\n","Original test accuracy:  0.9900000095367432\n","Pruned test accuracy:    0.9983333349227905\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmp_xj_qw5l/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmp_xj_qw5l/assets\n"]},{"name":"stdout","output_type":"stream","text":["Size of gzipped baseline Keras model: 48768.00 bytes\n","Size of gzipped pruned Keras model  : 21316.00 bytes\n","Size of gzipped pruned TFlite model : 19784.00 bytes\n","Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," prune_low_magnitude_conv2d_  (None, 26, 26, 8)        154       \n"," 8 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 24, 24, 8)        1162      \n"," 9 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_max_poo  (None, 12, 12, 8)        1         \n"," ling2d_4 (PruneLowMagnitude                                     \n"," )                                                               \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 10, 10, 32)       4642      \n"," 10 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_conv2d_  (None, 8, 8, 32)         18466     \n"," 11 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_max_poo  (None, 4, 4, 32)         1         \n"," ling2d_5 (PruneLowMagnitude                                     \n"," )                                                               \n","                                                                 \n"," prune_low_magnitude_dropout  (None, 4, 4, 32)         1         \n"," _2 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_flatten  (None, 512)              1         \n"," _2 (PruneLowMagnitude)                                          \n","                                                                 \n","=================================================================\n","Total params: 24,428\n","Trainable params: 12,248\n","Non-trainable params: 12,180\n","_________________________________________________________________\n","Save FROZEN PRUNED MODEL model as OMV_Frozen_pruned_cnn.h5\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stderr","output_type":"stream","text":["2022-10-24 23:35:50.958472: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n","2022-10-24 23:35:50.958489: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n","2022-10-24 23:35:50.958647: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmp_xj_qw5l\n","2022-10-24 23:35:50.960674: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n","2022-10-24 23:35:50.960693: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmp_xj_qw5l\n","2022-10-24 23:35:50.968469: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n","2022-10-24 23:35:51.002092: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmp_xj_qw5l\n","2022-10-24 23:35:51.014301: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 55664 microseconds.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmpll22r54i/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmpll22r54i/assets\n"]},{"name":"stdout","output_type":"stream","text":["18/32 [===============>..............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["2022-10-24 23:35:53.584067: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n","2022-10-24 23:35:53.584084: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n","2022-10-24 23:35:53.584205: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmpll22r54i\n","2022-10-24 23:35:53.586042: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n","2022-10-24 23:35:53.586054: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmpll22r54i\n","2022-10-24 23:35:53.592049: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n","2022-10-24 23:35:53.620216: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/48/lcqkmdxs143dt92dvrnfr3nh0000gn/T/tmpll22r54i\n","2022-10-24 23:35:53.633978: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 49772 microseconds.\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 3ms/step\n","58.61464843750001\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/Users/andrea/Documents/VS Code/MachineLearning/Models/Frozen_Pruned_model/ll_features_p_10.txt'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [69], line 143\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mprint\u001b[39m(count\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(features[:,\u001b[39m1\u001b[39m])\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(features[\u001b[39m1\u001b[39m,:])\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[39m######\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m np\u001b[39m.\u001b[39;49msavetxt(FROZEN_PRUNED_MODEL_PATH \u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mll_features_p_10.txt\u001b[39;49m\u001b[39m'\u001b[39;49m,features, fmt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%.3f\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(FROZEN_PRUNED_MODEL_PATH \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mll_features_p_10.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m new_file:\n\u001b[1;32m    147\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n","File \u001b[0;32m~/Documents/VS Code/MachineLearning/venv/lib/python3.10/site-packages/numpy/lib/npyio.py:1498\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m _is_string_like(fname):\n\u001b[1;32m   1497\u001b[0m     \u001b[39m# datasource doesn't support creating a new file ...\u001b[39;00m\n\u001b[0;32m-> 1498\u001b[0m     \u001b[39mopen\u001b[39;49m(fname, \u001b[39m'\u001b[39;49m\u001b[39mwt\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1499\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39m_datasource\u001b[39m.\u001b[39mopen(fname, \u001b[39m'\u001b[39m\u001b[39mwt\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[1;32m   1500\u001b[0m     own_fh \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/andrea/Documents/VS Code/MachineLearning/Models/Frozen_Pruned_model/ll_features_p_10.txt'"]}],"source":["from tensorflow.keras.models import load_model\n","import tensorflow_model_optimization as tfmot\n","\n","\n","####\n","prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","# Compute end step to finish pruning after n epochs.\n","batch_size = 32\n","epochs = 5\n","validation_split = 0.1  # 10% of training set will be used for validation set. \n","\n","num_images = data_low_train.shape[0] * (1 - validation_split)\n","end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n","\n","# Define model for pruning.\n","pruning_params = {\n","    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n","                                                               final_sparsity=0.80,\n","                                                               begin_step=0,\n","                                                               end_step=end_step)\n","}\n","\n","\n","model_for_pruning = prune_low_magnitude(model_test, **pruning_params)\n","\n","# `prune_low_magnitude` requires a recompile.\n","\n","# Select appropriate optimizer\n","model_for_pruning.compile(optimizer='adam',\n","                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                          metrics=['accuracy'])\n","\n","model_for_pruning.summary()\n","\n","\n","\n","\n","#####\n","logdir = tempfile.mkdtemp()\n","\n","callbacks = [\n","  tfmot.sparsity.keras.UpdatePruningStep(),\n","  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n","]\n","\n","model_for_pruning.fit(data_low_train, label_low_train,\n","                    batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks)\n","\n","\n","\n","####\n","_, model_for_pruning_accuracy = model_for_pruning.evaluate(data_low_test, label_low_test, verbose=0)\n","\n","print('Original test accuracy: ', test_acc)\n","print('Pruned test accuracy:   ', model_for_pruning_accuracy)\n","\n","\n","####\n","# First, create a compressible model for TensorFlow\n","\n","PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"/Pruned_model\"\n","\n","\n","model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","model_for_export.save(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.h5', include_optimizer=False)\n","\n","\n","\n","\n","#####\n","# Then, create a compressible model for TFLite\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n","pruned_tflite_model = converter.convert()\n","\n","with open(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.tflite', 'wb') as f:\n","    f.write(pruned_tflite_model)\n","\n","\n","#####\n","print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n","print(\"Size of gzipped pruned Keras model  : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.h5')))\n","print(\"Size of gzipped pruned TFlite model : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.tflite')))\n","\n","\n","\n","\n","#####\n","frozen_pruned_model = keras.models.Sequential(model_for_pruning.layers[:-1])\n","frozen_pruned_model.summary()\n","frozen_pruned_model.compile()\n","\n","FROZEN_PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"/Frozen_Pruned_model\"\n","\n","print('Save FROZEN PRUNED MODEL model as OMV_Frozen_pruned_cnn.h5')\n","frozen_pruned_model.save(FROZEN_PRUNED_MODEL_PATH + \"OMV_Frozen_pruned_cnn.h5\")\n","info = save_info(batch_size, epochs, metrics, optimizer, \"SparseCategoricalCrossentropy\")\n","save_summary_model(frozen_pruned_model, FROZEN_PRUNED_MODEL_PATH, info, 'frozen')\n","\n","\n","\n","\n","#####\n","model_for_export2 = tfmot.sparsity.keras.strip_pruning(frozen_pruned_model)\n","model_for_export2.save(PRUNED_MODEL_PATH + '/OMV_Frozen_pruned_cnn.h5', include_optimizer=False)\n","\n","\n","\n","\n","###\n","converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export2)\n","pruned_tflite_fmodel = converter.convert()\n","\n","with open(PRUNED_MODEL_PATH + '/OMV_Pruned_cnn.tflite', 'wb') as f:\n","    f.write(pruned_tflite_fmodel)\n","\n","\n","\n","####\n","data_test = np.concatenate((data_low_test, data_high_test))\n","label_test = np.concatenate((label_low_test, label_high_test))\n","features = frozen_pruned_model.predict(data_test)\n","\n","\n","\n","\n","####\n","count = 0\n","\n","for i in range(0, len(features[:,1])):\n","  for j in range(0, len(features[1,:])):\n","    if features[i,j] == 0:\n","      count +=1\n","\n","print(count/len(features[:,1])/len(features[1,:])*100)\n","\n","\n","\n","\n","######\n","\n","np.savetxt(FROZEN_PRUNED_MODEL_PATH +'/'+'ll_features_p_10.txt',features, fmt='%.3f')\n","\n","with open(FROZEN_PRUNED_MODEL_PATH +'/'+'ll_features_p_10.txt', 'w') as new_file:\n","\n","    for i in range(0, features.shape[0]):\n","        for j in range(0, features.shape[1]): \n","            if features[i,j] != 0:\n","              str1 = '%.3f '%features[i,j]\n","            else:\n","              str1 = '0 '\n","\n","            new_file.write(str1)\n","            \n","        new_file.write('\\n')     \n","\n","new_file.close()\n","\n","np.savetxt(FROZEN_PRUNED_MODEL_PATH +'/'+'ll_labels_features_p_10.txt',label_test, fmt='%1d')"]},{"cell_type":"markdown","metadata":{"id":"SNAsXyqvh-nP"},"source":["Tflite frozen pruned"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.7 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"f7fd1b55a667aa91d3f88049cb2b0330e965cb77ee086e9d0bbb787b7ff82ca0"}}},"nbformat":4,"nbformat_minor":0}
